{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL/blob/master/tutorials/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mPT0ipYE28wL",
    "outputId": "5002eb1d-6fec-4458-a873-f5f6b6f57e5e"
   },
   "outputs": [],
   "source": [
    "# ## install finrl library\n",
    "#!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'finrl.config_tickers' from '/home/k/anaconda3/envs/finRL/lib/python3.8/site-packages/finrl/config_tickers.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "1234fde6-bb5a-4e64-b975-056fc3c0c95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TSLA', 'ZM', 'ROKU', 'EXAS', 'NTLA', 'SQ', 'TDOC', 'CRSP', 'COIN', 'PATH', 'BEAM', 'TWLO', 'U', 'SHOP', 'DKNG', 'UW', 'RBLX', 'DNA', 'HOOD', 'PD', 'FATE', 'TWST', 'TXG', 'NVDA', 'VCYT', 'PACB', 'SGFY', 'TSP', 'SPOT', 'NVTA', 'MTLS', 'TWOU', 'CERS', 'BLI', 'GEN']\n"
     ]
    }
   ],
   "source": [
    "print(config_tickers.ARK_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "83273b04-ff5c-457c-e3ed-ded275cb11a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (52942, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(start_date = '2009-04-01',\n",
    "                     end_date = '2022-09-11',\n",
    "                     ticker_list = config_tickers.ARK_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GiRuFOTOtj1Y",
    "outputId": "3ab9aca2-f0d9-4dac-a2da-a5cbafbf67d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>53200</td>\n",
       "      <td>CERS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.2300</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>25500</td>\n",
       "      <td>EXAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>14.680</td>\n",
       "      <td>15.110</td>\n",
       "      <td>14.6000</td>\n",
       "      <td>5.719993</td>\n",
       "      <td>12685100</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.525</td>\n",
       "      <td>2.4475</td>\n",
       "      <td>2.262837</td>\n",
       "      <td>80527200</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1100000</td>\n",
       "      <td>UW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high      low     close    volume   tic  day\n",
       "0  2009-03-31   0.680   0.680   0.6300  0.680000     53200  CERS    1\n",
       "1  2009-03-31   1.280   1.280   1.2300  1.250000     25500  EXAS    1\n",
       "2  2009-03-31  14.680  15.110  14.6000  5.719993  12685100   GEN    1\n",
       "3  2009-03-31   2.485   2.525   2.4475  2.262837  80527200  NVDA    1\n",
       "4  2009-03-31   0.065   0.065   0.0650  0.065000   1100000    UW    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DSw4ZEzVtj1Z",
    "outputId": "4bddf614-8b0a-4db1-8ae3-1ca2464dca99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52937</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>42.660000</td>\n",
       "      <td>44.580002</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>44.040001</td>\n",
       "      <td>542900</td>\n",
       "      <td>TWST</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52938</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>34.630001</td>\n",
       "      <td>35.990002</td>\n",
       "      <td>34.169998</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>754800</td>\n",
       "      <td>TXG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52939</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>39.700001</td>\n",
       "      <td>41.430000</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>16513300</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52940</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.959999</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>835800</td>\n",
       "      <td>VCYT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52941</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>81.589996</td>\n",
       "      <td>83.699997</td>\n",
       "      <td>81.540001</td>\n",
       "      <td>82.620003</td>\n",
       "      <td>3964000</td>\n",
       "      <td>ZM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close    volume   tic  \\\n",
       "52937  2022-09-09  42.660000  44.580002  42.000000  44.040001    542900  TWST   \n",
       "52938  2022-09-09  34.630001  35.990002  34.169998  35.900002    754800   TXG   \n",
       "52939  2022-09-09  39.700001  41.430000  39.580002  41.299999  16513300     U   \n",
       "52940  2022-09-09  19.690001  19.959999  19.120001  19.950001    835800  VCYT   \n",
       "52941  2022-09-09  81.589996  83.699997  81.540001  82.620003   3964000    ZM   \n",
       "\n",
       "       day  \n",
       "52937    4  \n",
       "52938    4  \n",
       "52939    4  \n",
       "52940    4  \n",
       "52941    4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "8d70f38a-153a-4814-bba1-de8b084cb13e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52942, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4hYkeaPiICHS",
    "outputId": "06337afc-3e17-488b-8941-cc6236f291cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>53200</td>\n",
       "      <td>CERS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.280</td>\n",
       "      <td>1.2300</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>25500</td>\n",
       "      <td>EXAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>14.680</td>\n",
       "      <td>15.110</td>\n",
       "      <td>14.6000</td>\n",
       "      <td>5.719993</td>\n",
       "      <td>12685100</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.525</td>\n",
       "      <td>2.4475</td>\n",
       "      <td>2.262837</td>\n",
       "      <td>80527200</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1100000</td>\n",
       "      <td>UW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high      low     close    volume   tic  day\n",
       "0  2009-03-31   0.680   0.680   0.6300  0.680000     53200  CERS    1\n",
       "1  2009-03-31   1.280   1.280   1.2300  1.250000     25500  EXAS    1\n",
       "2  2009-03-31  14.680  15.110  14.6000  5.719993  12685100   GEN    1\n",
       "3  2009-03-31   2.485   2.525   2.4475  2.262837  80527200  NVDA    1\n",
       "4  2009-03-31   0.065   0.065   0.0650  0.065000   1100000    UW    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2vryMsdNL9H",
    "outputId": "6032493a-ebe8-4f72-ab27-a7f4b5a650c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.tic.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcNyXa7RNPrF",
    "outputId": "9704f56f-9db0-4232-d1e5-c82c7db284df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CERS    3386\n",
       "GEN     3386\n",
       "NVDA    3386\n",
       "EXAS    3386\n",
       "TSLA    3072\n",
       "PACB    2988\n",
       "FATE    2252\n",
       "VCYT    2231\n",
       "TWOU    2129\n",
       "MTLS    2068\n",
       "UW      1971\n",
       "NVTA    1908\n",
       "SHOP    1841\n",
       "TDOC    1813\n",
       "SQ      1713\n",
       "NTLA    1598\n",
       "TWLO    1565\n",
       "CRSP    1483\n",
       "ROKU    1246\n",
       "SPOT    1119\n",
       "TWST     971\n",
       "PD       861\n",
       "ZM       856\n",
       "DKNG     789\n",
       "TXG      755\n",
       "BEAM     654\n",
       "BLI      542\n",
       "U        498\n",
       "SGFY     398\n",
       "RBLX     380\n",
       "COIN     356\n",
       "TSP      355\n",
       "DNA      353\n",
       "PATH     351\n",
       "HOOD     282\n",
       "Name: tic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>53200</td>\n",
       "      <td>CERS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>25500</td>\n",
       "      <td>EXAS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>5.719993</td>\n",
       "      <td>12685100</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>2.485000</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>2.447500</td>\n",
       "      <td>2.262837</td>\n",
       "      <td>80527200</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1100000</td>\n",
       "      <td>UW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52937</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>42.660000</td>\n",
       "      <td>44.580002</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>44.040001</td>\n",
       "      <td>542900</td>\n",
       "      <td>TWST</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52938</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>34.630001</td>\n",
       "      <td>35.990002</td>\n",
       "      <td>34.169998</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>754800</td>\n",
       "      <td>TXG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52939</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>39.700001</td>\n",
       "      <td>41.430000</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>16513300</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52940</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.959999</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>835800</td>\n",
       "      <td>VCYT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52941</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>81.589996</td>\n",
       "      <td>83.699997</td>\n",
       "      <td>81.540001</td>\n",
       "      <td>82.620003</td>\n",
       "      <td>3964000</td>\n",
       "      <td>ZM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52942 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close    volume   tic  \\\n",
       "0      2009-03-31   0.680000   0.680000   0.630000   0.680000     53200  CERS   \n",
       "1      2009-03-31   1.280000   1.280000   1.230000   1.250000     25500  EXAS   \n",
       "2      2009-03-31  14.680000  15.110000  14.600000   5.719993  12685100   GEN   \n",
       "3      2009-03-31   2.485000   2.525000   2.447500   2.262837  80527200  NVDA   \n",
       "4      2009-03-31   0.065000   0.065000   0.065000   0.065000   1100000    UW   \n",
       "...           ...        ...        ...        ...        ...       ...   ...   \n",
       "52937  2022-09-09  42.660000  44.580002  42.000000  44.040001    542900  TWST   \n",
       "52938  2022-09-09  34.630001  35.990002  34.169998  35.900002    754800   TXG   \n",
       "52939  2022-09-09  39.700001  41.430000  39.580002  41.299999  16513300     U   \n",
       "52940  2022-09-09  19.690001  19.959999  19.120001  19.950001    835800  VCYT   \n",
       "52941  2022-09-09  81.589996  83.699997  81.540001  82.620003   3964000    ZM   \n",
       "\n",
       "       day  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "...    ...  \n",
       "52937    4  \n",
       "52938    4  \n",
       "52939    4  \n",
       "52940    4  \n",
       "52941    4  \n",
       "\n",
       "[52942 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7ff023ddb6d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def month_df(df):\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year-month'] = df['date'].map(lambda x: x.strftime('%Y-%m'))\n",
    "    df = df.sort_values(['year-month', 'tic'], ascending=[True, True])\n",
    "    dfo = df.groupby('year-month')['open']\n",
    "    # df1['year'] = pd.DatetimeIndex(df1['date']).year\n",
    "    # df1['month'] = pd.DatetimeIndex(df1['date']).month\n",
    "    # df1.loc[df.groupby([\"year\",\"month\"])[\"high\"].idxmax()]\n",
    "    return dfo\n",
    "\n",
    "df1 = month_df(df)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>year-month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>53200</td>\n",
       "      <td>CERS</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>25500</td>\n",
       "      <td>EXAS</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>15.110000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>5.719993</td>\n",
       "      <td>12685100</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>2.485000</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>2.447500</td>\n",
       "      <td>2.262837</td>\n",
       "      <td>80527200</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-03-31</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>1100000</td>\n",
       "      <td>UW</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52937</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>42.660000</td>\n",
       "      <td>44.580002</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>44.040001</td>\n",
       "      <td>542900</td>\n",
       "      <td>TWST</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52938</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>34.630001</td>\n",
       "      <td>35.990002</td>\n",
       "      <td>34.169998</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>754800</td>\n",
       "      <td>TXG</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52939</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>39.700001</td>\n",
       "      <td>41.430000</td>\n",
       "      <td>39.580002</td>\n",
       "      <td>41.299999</td>\n",
       "      <td>16513300</td>\n",
       "      <td>U</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52940</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>19.690001</td>\n",
       "      <td>19.959999</td>\n",
       "      <td>19.120001</td>\n",
       "      <td>19.950001</td>\n",
       "      <td>835800</td>\n",
       "      <td>VCYT</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52941</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>81.589996</td>\n",
       "      <td>83.699997</td>\n",
       "      <td>81.540001</td>\n",
       "      <td>82.620003</td>\n",
       "      <td>3964000</td>\n",
       "      <td>ZM</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52942 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       open       high        low      close    volume   tic  \\\n",
       "0     2009-03-31   0.680000   0.680000   0.630000   0.680000     53200  CERS   \n",
       "1     2009-03-31   1.280000   1.280000   1.230000   1.250000     25500  EXAS   \n",
       "2     2009-03-31  14.680000  15.110000  14.600000   5.719993  12685100   GEN   \n",
       "3     2009-03-31   2.485000   2.525000   2.447500   2.262837  80527200  NVDA   \n",
       "4     2009-03-31   0.065000   0.065000   0.065000   0.065000   1100000    UW   \n",
       "...          ...        ...        ...        ...        ...       ...   ...   \n",
       "52937 2022-09-09  42.660000  44.580002  42.000000  44.040001    542900  TWST   \n",
       "52938 2022-09-09  34.630001  35.990002  34.169998  35.900002    754800   TXG   \n",
       "52939 2022-09-09  39.700001  41.430000  39.580002  41.299999  16513300     U   \n",
       "52940 2022-09-09  19.690001  19.959999  19.120001  19.950001    835800  VCYT   \n",
       "52941 2022-09-09  81.589996  83.699997  81.540001  82.620003   3964000    ZM   \n",
       "\n",
       "       day year-month  \n",
       "0        1    2009-03  \n",
       "1        1    2009-03  \n",
       "2        1    2009-03  \n",
       "3        1    2009-03  \n",
       "4        1    2009-03  \n",
       "...    ...        ...  \n",
       "52937    4    2022-09  \n",
       "52938    4    2022-09  \n",
       "52939    4    2022-09  \n",
       "52940    4    2022-09  \n",
       "52941    4    2022-09  \n",
       "\n",
       "[52942 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from stockstats import wrap\n",
    "# df1 = df\n",
    "# df = wrap(df1)\n",
    "# df.init_all()\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kM5bH9uroCeg"
   },
   "outputs": [],
   "source": [
    "tech_indicators = [\"macd\",\"macds\",\"macdh\",\n",
    "    \"boll_ub\",\"boll\",\n",
    "    \"boll_lb\",\n",
    "    \"rsi_13\",\"rsi_21\",\"rsi_34\",\"rsi_55\",\"rsi_89\",\n",
    "    \"cci_30\",\n",
    "    \"dx_30\"]\n",
    "# 'rsi_14', 'stochrsi','close_10_sma', 'close_50_sma','close_3_sma', 'close_5_sma', 'macd','atr_14'\n",
    "                  \n",
    "# 'change', 'rsi', 'rsi_14', 'stochrsi', 'rate', 'middle', 'tp', 'boll',\n",
    "#                    'boll_ub', 'boll_lb', 'macd', 'macds', 'macdh', 'ppo', 'ppos', 'ppoh',\n",
    "#                    'rsv_9', 'kdjk_9', 'kdjk', 'kdjd_9', 'kdjd', 'kdjj_9', 'kdjj', 'cr',\n",
    "#                    'cr-ma1', 'cr-ma2', 'cr-ma3', 'cci', 'tr', 'atr', 'high_delta', 'um',\n",
    "#                    'low_delta', 'dm', 'atr_14', 'pdi_14',\n",
    "#                    'pdi', 'mdi_14', 'mdi', 'dx_14', 'dx',\n",
    "#                    'adx', 'adxr', 'trix', 'tema', 'vr', 'close_10_sma', 'close_50_sma',\n",
    "#                    'dma', 'vwma', 'chop', 'log-ret', 'mfi', 'wt1', 'wt2', 'wr',\n",
    "#                    'supertrend_ub', 'supertrend_lb', 'supertrend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgXfBcjxtj1a",
    "outputId": "154d8810-e754-448b-b340-2f3f63996c43",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = tech_indicators,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "processed = processed.copy()\n",
    "processed = processed.fillna(0)\n",
    "processed = processed.replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "grvhGJJII3Xn",
    "outputId": "467b45da-4b42-4a38-88a2-b77eb07afde2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>year-month</th>\n",
       "      <th>macd</th>\n",
       "      <th>...</th>\n",
       "      <th>boll</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_13</th>\n",
       "      <th>rsi_21</th>\n",
       "      <th>rsi_34</th>\n",
       "      <th>rsi_55</th>\n",
       "      <th>rsi_89</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>2013-11-26</td>\n",
       "      <td>23.080000</td>\n",
       "      <td>23.260000</td>\n",
       "      <td>22.670000</td>\n",
       "      <td>8.865039</td>\n",
       "      <td>10093600</td>\n",
       "      <td>GEN</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-11</td>\n",
       "      <td>-0.059021</td>\n",
       "      <td>...</td>\n",
       "      <td>8.98085</td>\n",
       "      <td>8.717010</td>\n",
       "      <td>40.478560</td>\n",
       "      <td>41.890024</td>\n",
       "      <td>43.513935</td>\n",
       "      <td>45.854051</td>\n",
       "      <td>48.466276</td>\n",
       "      <td>-35.734452</td>\n",
       "      <td>31.880109</td>\n",
       "      <td>6.522020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>2018-02-15</td>\n",
       "      <td>49.400002</td>\n",
       "      <td>49.580002</td>\n",
       "      <td>48.169998</td>\n",
       "      <td>49.139999</td>\n",
       "      <td>1921100</td>\n",
       "      <td>EXAS</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-02</td>\n",
       "      <td>-1.097853</td>\n",
       "      <td>...</td>\n",
       "      <td>48.78550</td>\n",
       "      <td>45.229669</td>\n",
       "      <td>49.382984</td>\n",
       "      <td>47.765532</td>\n",
       "      <td>48.260500</td>\n",
       "      <td>49.963155</td>\n",
       "      <td>51.950813</td>\n",
       "      <td>-34.998437</td>\n",
       "      <td>32.554490</td>\n",
       "      <td>2.846607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>6.240000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.090000</td>\n",
       "      <td>6.190000</td>\n",
       "      <td>1146400</td>\n",
       "      <td>CERS</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09</td>\n",
       "      <td>-0.119444</td>\n",
       "      <td>...</td>\n",
       "      <td>6.24100</td>\n",
       "      <td>5.787109</td>\n",
       "      <td>42.889527</td>\n",
       "      <td>44.541274</td>\n",
       "      <td>47.430815</td>\n",
       "      <td>49.831290</td>\n",
       "      <td>50.978113</td>\n",
       "      <td>-58.715904</td>\n",
       "      <td>1.921186</td>\n",
       "      <td>4.504176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>4.790000</td>\n",
       "      <td>4.830000</td>\n",
       "      <td>4.670000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>1082600</td>\n",
       "      <td>CERS</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-07</td>\n",
       "      <td>-0.208103</td>\n",
       "      <td>...</td>\n",
       "      <td>5.19150</td>\n",
       "      <td>4.469798</td>\n",
       "      <td>33.303149</td>\n",
       "      <td>36.702101</td>\n",
       "      <td>39.954425</td>\n",
       "      <td>42.802443</td>\n",
       "      <td>45.227172</td>\n",
       "      <td>-110.530993</td>\n",
       "      <td>34.810411</td>\n",
       "      <td>0.345333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9528</th>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>7.480000</td>\n",
       "      <td>7.240000</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>704200</td>\n",
       "      <td>CERS</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-09</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>...</td>\n",
       "      <td>7.29600</td>\n",
       "      <td>6.750110</td>\n",
       "      <td>48.314580</td>\n",
       "      <td>50.485623</td>\n",
       "      <td>52.765882</td>\n",
       "      <td>54.890483</td>\n",
       "      <td>56.092493</td>\n",
       "      <td>28.388810</td>\n",
       "      <td>9.701664</td>\n",
       "      <td>1.416592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       open       high        low      close    volume   tic  \\\n",
       "4698  2013-11-26  23.080000  23.260000  22.670000   8.865039  10093600   GEN   \n",
       "8945  2018-02-15  49.400002  49.580002  48.169998  49.139999   1921100  EXAS   \n",
       "11556 2020-09-21   6.240000   6.250000   6.090000   6.190000   1146400  CERS   \n",
       "12408 2021-07-27   4.790000   4.830000   4.670000   4.800000   1082600  CERS   \n",
       "9528  2018-09-14   7.350000   7.480000   7.240000   7.250000    704200  CERS   \n",
       "\n",
       "       day year-month      macd  ...      boll    boll_lb     rsi_13  \\\n",
       "4698     1    2013-11 -0.059021  ...   8.98085   8.717010  40.478560   \n",
       "8945     3    2018-02 -1.097853  ...  48.78550  45.229669  49.382984   \n",
       "11556    0    2020-09 -0.119444  ...   6.24100   5.787109  42.889527   \n",
       "12408    1    2021-07 -0.208103  ...   5.19150   4.469798  33.303149   \n",
       "9528     4    2018-09  0.021941  ...   7.29600   6.750110  48.314580   \n",
       "\n",
       "          rsi_21     rsi_34     rsi_55     rsi_89      cci_30      dx_30  \\\n",
       "4698   41.890024  43.513935  45.854051  48.466276  -35.734452  31.880109   \n",
       "8945   47.765532  48.260500  49.963155  51.950813  -34.998437  32.554490   \n",
       "11556  44.541274  47.430815  49.831290  50.978113  -58.715904   1.921186   \n",
       "12408  36.702101  39.954425  42.802443  45.227172 -110.530993  34.810411   \n",
       "9528   50.485623  52.765882  54.890483  56.092493   28.388810   9.701664   \n",
       "\n",
       "       turbulence  \n",
       "4698     6.522020  \n",
       "8945     2.846607  \n",
       "11556    4.504176  \n",
       "12408    0.345333  \n",
       "9528     1.416592  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "6f958c23-155e-4bb0-f91d-8627d176fa3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 4, State Space: 61\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(tech_indicators)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicators,\n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "train_start = '2009-04-01'\n",
    "train_end = '2020-04-01'\n",
    "val_test_start = '2020-04-01'\n",
    "val_test_end = '2022-09-11'\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
    "                 train_period=(train_start,train_end),\n",
    "                 val_test_period=(val_test_start,val_test_end),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.01,\n",
    "                    'learning_rate': 0.0005\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 10_000,\n",
    "                      \"learning_rate\": 0.0005,\n",
    "                      \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 50_000, \n",
    "                 'ppo' : 50_000, \n",
    "                 'ddpg' : 50_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1lyCECstj1e",
    "outputId": "634f65a8-abf7-43fc-ef7f-b15799746448",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2020-04-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_126_9\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 425         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.083      |\n",
      "|    reward             | -0.00483914 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.0179      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 520        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 6.55       |\n",
      "|    reward             | 0.23564361 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.3        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 563        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | -0.6154562 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 8.66       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 588        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | -0.0306    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -23.3      |\n",
      "|    reward             | 0.12299211 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 20.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 602       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 19.3      |\n",
      "|    reward             | 1.4257683 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 21.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 613         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -2.73       |\n",
      "|    reward             | 0.012908171 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.219       |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 621      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -1.66    |\n",
      "|    reward             | 0.284224 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.142    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 627       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 47.5      |\n",
      "|    reward             | 2.2735863 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 75        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 631        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -0.173     |\n",
      "|    reward             | 0.45769265 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.889      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 635        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -55.6      |\n",
      "|    reward             | -20.559347 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 130        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 639      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -36.8    |\n",
      "|    reward             | 7.761972 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 110      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 642         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 1.36        |\n",
      "|    reward             | -0.13394581 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.568       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 642          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.87        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.114955276 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.0835       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 6.01       |\n",
      "|    reward             | -1.3367765 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 8.67       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 646        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -45.6      |\n",
      "|    reward             | -3.1425638 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 82.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 647       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 67.8      |\n",
      "|    reward             | 6.3254833 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 181       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 649        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 1.23       |\n",
      "|    reward             | 0.28128034 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0646     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -1.2      |\n",
      "|    reward             | 0.5987619 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.115     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -16.7     |\n",
      "|    reward             | 3.0296793 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 10.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 5.3444066 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 6.84      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -47.4      |\n",
      "|    reward             | 0.33331928 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 55.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0.0048    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 1.0031679 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 9.65      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 655         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | -0.18878144 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.0101      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -7.3       |\n",
      "|    reward             | 0.18837419 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.67       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 656          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.92        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | 7.76         |\n",
      "|    reward             | -0.038521137 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 3.06         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 41.7       |\n",
      "|    reward             | -3.4871323 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 66.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 658       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0.00717   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 117       |\n",
      "|    reward             | -7.364626 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 523       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2769, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2942448.87\n",
      "total_reward: 1942448.87\n",
      "total_cost: 6096.13\n",
      "total_trades: 6868\n",
      "Sharpe: 0.502\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -0.674     |\n",
      "|    reward             | 0.15726289 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.0318     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 659         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | 3.17        |\n",
      "|    reward             | -0.23568195 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.736       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 659       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 5.08      |\n",
      "|    reward             | 0.6174559 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.643     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 660         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -5.43       |\n",
      "|    reward             | -0.39525837 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 1.2         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 661       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 15.6      |\n",
      "|    reward             | 0.9870796 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 7.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 661      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 6.6      |\n",
      "|    reward             | 0.625898 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 6.91     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 661         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.98       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | 1.45        |\n",
      "|    reward             | -0.12761098 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.126       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 660         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | 0.953       |\n",
      "|    reward             | -0.24357264 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0561      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 660        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 0.262      |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -2.75      |\n",
      "|    reward             | 0.47886163 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.83       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 661       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -28.7     |\n",
      "|    reward             | 1.5819198 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 50.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 661       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -145      |\n",
      "|    reward             | 11.060046 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 683       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 661        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 0.424      |\n",
      "|    reward             | 0.14063026 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.0151     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 662        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | 5.12       |\n",
      "|    reward             | -0.6487774 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 1.79       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 663         |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 30          |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6          |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -10.3       |\n",
      "|    reward             | -0.41164553 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 3.22        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 663       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -5.72     |\n",
      "|    reward             | -5.081197 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.58      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 663         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.98       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -111        |\n",
      "|    reward             | -14.0564165 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 452         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 664        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | -0.00023   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -116       |\n",
      "|    reward             | -23.677355 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 1.43e+03   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 664           |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6            |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | -3.13         |\n",
      "|    reward             | -0.0041811033 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.594         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 664         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6          |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | -8.46       |\n",
      "|    reward             | -0.63362426 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 4.1         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 663       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -6.71     |\n",
      "|    reward             | 1.5039613 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.67      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 663      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6       |\n",
      "|    explained_variance | -0.0423  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -1.06    |\n",
      "|    reward             | 4.149205 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.81     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 663       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 33.9      |\n",
      "|    reward             | -6.035097 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 280       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6          |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.593      |\n",
      "|    reward             | 0.035464074 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0117      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6          |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -1.02       |\n",
      "|    reward             | -0.23489152 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0993      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 661       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -7.49     |\n",
      "|    reward             | 0.1555014 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 661        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | -0.628     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 5.48       |\n",
      "|    reward             | -1.2972684 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 1.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 661       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | -0.000345 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -20.8     |\n",
      "|    reward             | 7.6738467 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 171       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 661       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | -0.000201 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 144       |\n",
      "|    reward             | 27.283234 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 564       |\n",
      "-------------------------------------\n",
      "day: 2769, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7691772.44\n",
      "total_reward: 6691772.44\n",
      "total_cost: 7556.81\n",
      "total_trades: 8822\n",
      "Sharpe: 0.794\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 661        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 1.25       |\n",
      "|    reward             | 0.19613805 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.178      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 43          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 0.494       |\n",
      "|    reward             | 0.012732856 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.141       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 662        |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 8.74       |\n",
      "|    reward             | -1.2726717 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.33       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | -0.216      |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 71.2        |\n",
      "|    reward             | -0.03587787 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 170         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 662       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 26.6      |\n",
      "|    reward             | -5.282882 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 203       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.462      |\n",
      "|    reward             | 0.010354716 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.00852     |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 662      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 0.0255   |\n",
      "|    reward             | 1.083323 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.148    |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.02       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 8.8         |\n",
      "|    reward             | -0.17951186 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 7.32        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 662         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 18.2        |\n",
      "|    reward             | -0.20518745 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 14.1        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 662       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | -0.000818 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 30.2      |\n",
      "|    reward             | 5.701084  |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 40.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 663       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0.000455  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -2.11     |\n",
      "|    reward             | 3.3357472 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 21.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 663        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 2.73       |\n",
      "|    reward             | 0.17346278 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.374      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 663         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | 16.7        |\n",
      "|    reward             | -0.24802384 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 5.58        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 663       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -42.2     |\n",
      "|    reward             | -8.075573 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 54.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 663        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | -0.0791    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 11.5       |\n",
      "|    reward             | 0.87677425 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 5.56       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 663        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.03      |\n",
      "|    explained_variance | -0.0113    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 21.7       |\n",
      "|    reward             | -28.566578 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 39.4       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 664       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.03     |\n",
      "|    explained_variance | -0.00132  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -849      |\n",
      "|    reward             | 107.82359 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.9e+04   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 664        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -12.2      |\n",
      "|    reward             | 0.06837814 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 4.53       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 664        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 20.1       |\n",
      "|    reward             | 0.39553335 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 14.4       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.06    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -36.3    |\n",
      "|    reward             | 5.439463 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 70.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 664       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 7.87      |\n",
      "|    reward             | 10.869242 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 14.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 664      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.07    |\n",
      "|    explained_variance | 0.0951   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 38.6     |\n",
      "|    reward             | 68.79854 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 172      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 664        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 0.96       |\n",
      "|    reward             | 0.19479778 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.053      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 664        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 3.84       |\n",
      "|    reward             | 0.11930531 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.667      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 665         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -52.5       |\n",
      "|    reward             | -0.94269633 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 92.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 665        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -2.7       |\n",
      "|    reward             | -1.0583757 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 1.82       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 665       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.11     |\n",
      "|    explained_variance | 0.0113    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -113      |\n",
      "|    reward             | -6.291779 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 563       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 665       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.11     |\n",
      "|    explained_variance | -0.00216  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -185      |\n",
      "|    reward             | 48.314564 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.01e+03  |\n",
      "-------------------------------------\n",
      "day: 2769, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8202774.21\n",
      "total_reward: 7202774.21\n",
      "total_cost: 7208.58\n",
      "total_trades: 9055\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 665         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.13       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 3.23        |\n",
      "|    reward             | -0.07540363 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.323       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 665        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.13      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 9.34       |\n",
      "|    reward             | -0.3261493 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 3.25       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 665        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.14      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 32.8       |\n",
      "|    reward             | -0.3260489 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 52.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 665        |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.16      |\n",
      "|    explained_variance | -0.344     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | -18.9      |\n",
      "|    reward             | -2.0928805 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 16.5       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 665        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -75.6      |\n",
      "|    reward             | -2.1763499 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 205        |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 665           |\n",
      "|    iterations         | 8900          |\n",
      "|    time_elapsed       | 66            |\n",
      "|    total_timesteps    | 44500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.16         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 8899          |\n",
      "|    policy_loss        | -0.523        |\n",
      "|    reward             | -0.0047481954 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 0.00386       |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 665       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 5.29      |\n",
      "|    reward             | 0.1317051 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 15.6      |\n",
      "|    reward             | 0.6431132 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 12.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -3.55      |\n",
      "|    reward             | -1.0036141 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 1.61       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.16     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 0.651     |\n",
      "|    reward             | -4.963183 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 30.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.16      |\n",
      "|    explained_variance | 0.00197    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -13.2      |\n",
      "|    reward             | -15.697539 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 32.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.16      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | -3.15      |\n",
      "|    reward             | 0.81096214 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 0.375      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.18      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -20.9      |\n",
      "|    reward             | 0.73519224 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 9.08       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0.0215     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 48.2       |\n",
      "|    reward             | -13.888306 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 61.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 35.4      |\n",
      "|    reward             | 0.9212952 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 29.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -115      |\n",
      "|    reward             | 28.841196 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 503       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 666         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 74          |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.18       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 0.206       |\n",
      "|    reward             | -0.14864925 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.00234     |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2020-04-02T00:00:00.000000000 to  2020-07-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.15889926177084113\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_126_9\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 866        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 2          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | -0.1132665 |\n",
      "-----------------------------------\n",
      "day: 2769, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1158250.73\n",
      "total_reward: 158250.73\n",
      "total_cost: 9762.75\n",
      "total_trades: 10828\n",
      "Sharpe: 0.198\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 777          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049612643 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0229      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | 0.37090912   |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.0439       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 752         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006022457 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | 0.40988484  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 740         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006424725 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | -0.000636   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    reward               | 4.414694    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 62.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 735          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039015056 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | -0.0339      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    reward               | -0.19559121  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 47.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006726459 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.16        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    reward               | -0.10466883 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 43.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056236703 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0497       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 24.1         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | -0.064113356 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00596998  |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0.00824     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    reward               | -0.15977731 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "day: 2769, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1390857.28\n",
      "total_reward: 390857.28\n",
      "total_cost: 9919.19\n",
      "total_trades: 10908\n",
      "Sharpe: 0.407\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054882085 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -0.0031      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.676        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 1.145453     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.6          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069528855 |\n",
      "|    clip_fraction        | 0.0587       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.00235      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.12         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    reward               | 1.6078293    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003944182 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.28        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | 0.07935901  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063303737 |\n",
      "|    clip_fraction        | 0.0764       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.0202       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | 2.06935      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 31.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052147023 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.92         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 0.10487579   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 21.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015014966 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.00829      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -8.76e-05    |\n",
      "|    reward               | 0.057637423  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 44           |\n",
      "------------------------------------------\n",
      "day: 2769, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1695698.43\n",
      "total_reward: 695698.43\n",
      "total_cost: 9703.33\n",
      "total_trades: 10807\n",
      "Sharpe: 0.333\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005334473 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.0507      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.29        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | 0.00265273  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 20.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003434723 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    reward               | 0.17127933  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018613231 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.1          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 0.000979     |\n",
      "|    reward               | 0.056877576  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 5.42         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055949693 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.143        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.56         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    reward               | -0.1278521   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 30           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036908004 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.0681       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 25.7         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.014492976 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 74.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009195948 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.24        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | 0.1689995   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005875542 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.81       |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | -0.88833076 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 4.23        |\n",
      "-----------------------------------------\n",
      "day: 2769, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1421893.81\n",
      "total_reward: 421893.81\n",
      "total_cost: 9437.92\n",
      "total_trades: 10562\n",
      "Sharpe: 0.320\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004736001 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.36        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.000191   |\n",
      "|    reward               | -0.19033507 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 10.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006749887 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | -0.00286    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.71        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.000469    |\n",
      "|    reward               | 0.003443273 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061745704 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.00323      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.45         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000977    |\n",
      "|    reward               | -0.92963845  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071981465 |\n",
      "|    clip_fraction        | 0.0728       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.0874       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.427        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.076664604  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.04         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2020-04-02T00:00:00.000000000 to  2020-07-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.31854080429521886\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_8\n",
      "day: 2769, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6578365.81\n",
      "total_reward: 5578365.81\n",
      "total_cost: 7403.46\n",
      "total_trades: 2769\n",
      "Sharpe: 0.594\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 431       |\n",
      "|    time_elapsed    | 25        |\n",
      "|    total_timesteps | 11080     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.23e+03 |\n",
      "|    critic_loss     | 1.16e+05  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 8310      |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 2769, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 393       |\n",
      "|    time_elapsed    | 56        |\n",
      "|    total_timesteps | 22160     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.73e+03 |\n",
      "|    critic_loss     | 2.21e+04  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 19390     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 2769, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 381       |\n",
      "|    time_elapsed    | 87        |\n",
      "|    total_timesteps | 33240     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.66e+03 |\n",
      "|    critic_loss     | 5.76e+03  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 30470     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 375       |\n",
      "|    time_elapsed    | 118       |\n",
      "|    total_timesteps | 44320     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.06e+03 |\n",
      "|    critic_loss     | 1.61e+03  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 41550     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 2769, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "======DDPG Validation from:  2020-04-02T00:00:00.000000000 to  2020-07-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2020-07-02T00:00:00.000000000\n",
      "======Trading from:  2020-07-02T00:00:00.000000000 to  2020-10-01T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2020-07-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_189_8\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 674         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | 0.0239      |\n",
      "|    reward             | 0.022759909 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.0261      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 670       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -1.09     |\n",
      "|    reward             | 0.2666685 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.0379    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 671       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -7.83     |\n",
      "|    reward             | 0.5701082 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 2.2       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -8.8     |\n",
      "|    reward             | 3.531755 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.82     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 671       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 8.63e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -7.81     |\n",
      "|    reward             | 1.9605918 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 7.24      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 671         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -0.312      |\n",
      "|    reward             | -0.14082019 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.00636     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 671         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.257       |\n",
      "|    reward             | -0.18400937 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.695       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 671       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 13.3      |\n",
      "|    reward             | -1.255431 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 6.64      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 671        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 15         |\n",
      "|    reward             | -1.2759162 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 22.9       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.88    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 118      |\n",
      "|    reward             | 8.017192 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 556      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 672       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 89        |\n",
      "|    reward             | 1.3346366 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 298       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 671         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 0.133       |\n",
      "|    reward             | -0.42202196 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.054       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 671        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 1.95       |\n",
      "|    reward             | -1.0224864 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.163      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 671       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.06      |\n",
      "|    reward             | 1.7429427 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.97      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 672         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 30.6        |\n",
      "|    reward             | -0.58927435 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 30.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 672       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 8.98      |\n",
      "|    reward             | 10.011301 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 183       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -275       |\n",
      "|    reward             | -1.9200428 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.78e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 672       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 6.1       |\n",
      "|    reward             | 1.2196147 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.814     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 672         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | -0.42302373 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 3.69        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 672       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 8.48e-05  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 7.23      |\n",
      "|    reward             | 3.2024212 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 8.64      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 671        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -38.2      |\n",
      "|    reward             | -0.7422397 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 71.6       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 671      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.89    |\n",
      "|    explained_variance | -0.0337  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -62.2    |\n",
      "|    reward             | 51.12754 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 125      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 671         |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -2.44       |\n",
      "|    reward             | 0.011426113 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.255       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 2.92       |\n",
      "|    reward             | 0.96410286 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | 7.84       |\n",
      "|    reward             | -0.9595323 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 6.09       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0.018      |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 51.6       |\n",
      "|    reward             | -1.6413009 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 84.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 100        |\n",
      "|    reward             | -7.0061717 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 641        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | 58.8       |\n",
      "|    reward             | -2.6635447 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 288        |\n",
      "--------------------------------------\n",
      "day: 2832, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 13313397.36\n",
      "total_reward: 12313397.36\n",
      "total_cost: 6772.67\n",
      "total_trades: 10659\n",
      "Sharpe: 0.951\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | 1.81       |\n",
      "|    reward             | 0.17913623 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.231      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -1.91      |\n",
      "|    reward             | -0.9839174 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 16.5       |\n",
      "|    reward             | -0.3218247 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 7.62       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 671       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0.00777   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 46.5      |\n",
      "|    reward             | -1.057214 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 70.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 671        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | -0.00121   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -11.4      |\n",
      "|    reward             | -11.444296 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 46.1       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 671          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.9         |\n",
      "|    explained_variance | 0.00887      |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -110         |\n",
      "|    reward             | 0.0014592287 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 600          |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 2.36       |\n",
      "|    reward             | 0.47668827 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.393      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 672         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -11.5       |\n",
      "|    reward             | -0.05382781 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 4.96        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 672       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -0.0347   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    reward             | 1.1324364 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 8.7       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 672       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 4.32      |\n",
      "|    reward             | 0.7766279 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.99      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 672      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.89    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -87.9    |\n",
      "|    reward             | 8.605959 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 332      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 672        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -1.78      |\n",
      "|    reward             | 0.24821058 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.166      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 669       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 1.99      |\n",
      "|    reward             | -3.167562 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 669      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.91    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 10.2     |\n",
      "|    reward             | 0.525623 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 8.97     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 669       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -18       |\n",
      "|    reward             | 1.6817579 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 7.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 669       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0.000141  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 6.16      |\n",
      "|    reward             | -9.881501 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 134       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 670        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | -0.00521   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -210       |\n",
      "|    reward             | -17.840052 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.14e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 670       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 4.68      |\n",
      "|    reward             | 0.2853766 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.981     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 670       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -17.6     |\n",
      "|    reward             | 4.5861588 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 6.98      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 669       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0.00399   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 15        |\n",
      "|    reward             | 1.7061892 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 11.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 669        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | 22         |\n",
      "|    reward             | -1.9265931 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 17.1       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 669      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.94    |\n",
      "|    explained_variance | 0.0106   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 69.2     |\n",
      "|    reward             | 9.910271 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 133      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 668            |\n",
      "|    iterations         | 5100           |\n",
      "|    time_elapsed       | 38             |\n",
      "|    total_timesteps    | 25500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -5.95          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0005         |\n",
      "|    n_updates          | 5099           |\n",
      "|    policy_loss        | 62.1           |\n",
      "|    reward             | -0.00094520603 |\n",
      "|    std                | 1.07           |\n",
      "|    value_loss         | 450            |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 668        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | 6.94       |\n",
      "|    reward             | 0.73717284 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 1.57       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 668        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -9.24      |\n",
      "|    reward             | -0.4468352 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 4.6        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 668        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 5.43       |\n",
      "|    reward             | -1.3026538 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.36       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 668       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -1.59     |\n",
      "|    reward             | 1.3147547 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.71      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -130      |\n",
      "|    reward             | 16.425602 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 412       |\n",
      "-------------------------------------\n",
      "day: 2832, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10867170.24\n",
      "total_reward: 9867170.24\n",
      "total_cost: 6712.08\n",
      "total_trades: 10553\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 667         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.372      |\n",
      "|    reward             | 0.061574545 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.0358      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -20.2     |\n",
      "|    reward             | -1.424967 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 13.8      |\n",
      "|    reward             | 2.7870715 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 8.71      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 667         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6          |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | -14         |\n",
      "|    reward             | 0.108354844 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 5.51        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | -0.00414  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -65.3     |\n",
      "|    reward             | 12.373395 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 166       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -30       |\n",
      "|    reward             | 3.5284474 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 41.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 3.77       |\n",
      "|    reward             | -0.3747345 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.441      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 666      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.01    |\n",
      "|    explained_variance | -0.293   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 3.5      |\n",
      "|    reward             | 1.859326 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.466    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.04     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 3.76      |\n",
      "|    reward             | 1.2560532 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.15      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | 73.5       |\n",
      "|    reward             | 0.51918167 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 137        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 123        |\n",
      "|    reward             | -3.8500469 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 418        |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 666           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 50            |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.04         |\n",
      "|    explained_variance | -0.000109     |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | 116           |\n",
      "|    reward             | -0.0038302876 |\n",
      "|    std                | 1.1           |\n",
      "|    value_loss         | 676           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 16.4      |\n",
      "|    reward             | 1.2059418 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 8.32      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -5.44      |\n",
      "|    reward             | 0.55618376 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 13.3       |\n",
      "|    reward             | -3.1038804 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 5.53       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 666      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 27.4     |\n",
      "|    reward             | 5.932241 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 32.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -127       |\n",
      "|    reward             | -7.9588523 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 358        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 7400       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 37000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.03      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7399       |\n",
      "|    policy_loss        | 0.56       |\n",
      "|    reward             | 0.12370785 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.0458     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.04     |\n",
      "|    explained_variance | 0.00856   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -38.1     |\n",
      "|    reward             | 5.2588067 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 28.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 7.75      |\n",
      "|    reward             | 0.7271877 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.6       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 666      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | -12      |\n",
      "|    reward             | 2.501917 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 7.31     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 33.5       |\n",
      "|    reward             | -15.696077 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 79.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | -0.000549 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -1.24     |\n",
      "|    reward             | 1.8713385 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 37.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 6.18       |\n",
      "|    reward             | 0.56493807 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -17.2     |\n",
      "|    reward             | 4.2675996 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 12.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | -2.9309356 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 9.32       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 54.7      |\n",
      "|    reward             | 1.6249654 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 135       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 149        |\n",
      "|    reward             | -2.1160076 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 917        |\n",
      "--------------------------------------\n",
      "day: 2832, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 15512631.80\n",
      "total_reward: 14512631.80\n",
      "total_cost: 5894.78\n",
      "total_trades: 9927\n",
      "Sharpe: 0.964\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 666         |\n",
      "|    iterations         | 8500        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 42500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.98       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8499        |\n",
      "|    policy_loss        | 60          |\n",
      "|    reward             | 0.014832111 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 695         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 15.1       |\n",
      "|    reward             | -0.5993147 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 6.68       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 4.45      |\n",
      "|    reward             | -1.527695 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.92      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 666        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.01      |\n",
      "|    explained_variance | -0.00178   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 6.62       |\n",
      "|    reward             | -7.4384108 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 4.95       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 666       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 76.8      |\n",
      "|    reward             | 12.686637 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 214       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -116      |\n",
      "|    reward             | 16.449522 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 514       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.01      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -0.774     |\n",
      "|    reward             | 0.18291982 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.0337     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 667          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 68           |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.02        |\n",
      "|    explained_variance | 0.00511      |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | -13.7        |\n",
      "|    reward             | -0.068346016 |\n",
      "|    std                | 1.09         |\n",
      "|    value_loss         | 10.9         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -10.1      |\n",
      "|    reward             | 0.50705487 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 2.93       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -21        |\n",
      "|    reward             | 0.88447046 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 22.4       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 667      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 15.8     |\n",
      "|    reward             | 6.270809 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 78.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 233        |\n",
      "|    reward             | -1.3806455 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 878        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -19.9      |\n",
      "|    reward             | 0.09696538 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 7.85       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -32.1      |\n",
      "|    reward             | -3.1556127 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 29.1       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 667        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -2.55      |\n",
      "|    reward             | -0.9479934 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.75       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 667       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 40.1      |\n",
      "|    reward             | -6.180687 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 70.3      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-07-02T00:00:00.000000000 to  2020-10-01T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.11694109449558816\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_189_8\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 863        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 2          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | -0.3513425 |\n",
      "-----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 772          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028009126 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.617        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000494    |\n",
      "|    reward               | -0.15034886  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.82         |\n",
      "------------------------------------------\n",
      "day: 2832, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2163143.77\n",
      "total_reward: 1163143.77\n",
      "total_cost: 10746.23\n",
      "total_trades: 11157\n",
      "Sharpe: 0.572\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 748          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057293107 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | -0.13666902  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 737          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050235493 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.00163      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.1         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    reward               | -1.8647324   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 17.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008658543 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.00189     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.4         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    reward               | 0.13025525  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.44        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 724          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046889004 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.98         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    reward               | 0.028228303  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041627903 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.77        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 11.3         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    reward               | 0.006830468  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 27.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 719          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062176636 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | -0.74329376  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 26.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003616001 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.638       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    reward               | -0.27512717 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "day: 2832, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2192642.21\n",
      "total_reward: 1192642.21\n",
      "total_cost: 10735.56\n",
      "total_trades: 11158\n",
      "Sharpe: 0.714\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031375722 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.58         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    reward               | 0.035702687  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 11.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063524162 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.82        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.11         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | 1.674617     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 11.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058543812 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | 0.00299      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.91         |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -0.38118505  |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 21.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067349775 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | -0.0365      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    reward               | -0.15305609  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 21.2         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045108367 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | -0.00222     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 41.4         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | 0.0485441    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 92           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004056443 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.85       |\n",
      "|    explained_variance   | 0.0366      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    reward               | -5.7680445  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076249945 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.75         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | 1.8674865    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 36.3         |\n",
      "------------------------------------------\n",
      "day: 2832, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3377616.41\n",
      "total_reward: 2377616.41\n",
      "total_cost: 10509.11\n",
      "total_trades: 11117\n",
      "Sharpe: 0.527\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053501627 |\n",
      "|    clip_fraction        | 0.0745       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.0979       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 37.5         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | 0.4447514    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057072463 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | 0.063        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 140          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    reward               | -0.010667951 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054922057 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 99.5         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    reward               | 1.8305885    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 197          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045224093 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.87        |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.1          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000899    |\n",
      "|    reward               | 0.37209868   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 16.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003263384 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    reward               | 0.30526575  |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046863565 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | 0.032        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 298          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | 12.969092    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 329          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054425723 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | 0.145        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 78           |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 1.2059801    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2832, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5297553.89\n",
      "total_reward: 4297553.89\n",
      "total_cost: 11121.62\n",
      "total_trades: 11086\n",
      "Sharpe: 0.605\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005370701 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.88       |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    reward               | -0.44145674 |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040442147 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.88        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 260          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | -0.122448325 |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 499          |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2020-07-02T00:00:00.000000000 to  2020-10-01T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.1526677020852204\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_8\n",
      "day: 2832, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1642390.57\n",
      "total_reward: 642390.57\n",
      "total_cost: 999.00\n",
      "total_trades: 2832\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 426       |\n",
      "|    time_elapsed    | 26        |\n",
      "|    total_timesteps | 11332     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.47e+03  |\n",
      "|    critic_loss     | 1.22e+04  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 8499      |\n",
      "|    reward          | 3.8873198 |\n",
      "----------------------------------\n",
      "day: 2832, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1642390.57\n",
      "total_reward: 642390.57\n",
      "total_cost: 999.00\n",
      "total_trades: 2832\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 382       |\n",
      "|    time_elapsed    | 59        |\n",
      "|    total_timesteps | 22664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.19e+03  |\n",
      "|    critic_loss     | 231       |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 19831     |\n",
      "|    reward          | 3.8873198 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 371       |\n",
      "|    time_elapsed    | 91        |\n",
      "|    total_timesteps | 33996     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 659       |\n",
      "|    critic_loss     | 77.2      |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 31163     |\n",
      "|    reward          | 3.8873198 |\n",
      "----------------------------------\n",
      "day: 2832, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1642390.57\n",
      "total_reward: 642390.57\n",
      "total_cost: 999.00\n",
      "total_trades: 2832\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 364       |\n",
      "|    time_elapsed    | 124       |\n",
      "|    total_timesteps | 45328     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 329       |\n",
      "|    critic_loss     | 21.1      |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 42495     |\n",
      "|    reward          | 3.8873198 |\n",
      "----------------------------------\n",
      "day: 2832, episode: 55\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1642390.57\n",
      "total_reward: 642390.57\n",
      "total_cost: 999.00\n",
      "total_trades: 2832\n",
      "Sharpe: 0.303\n",
      "=================================\n",
      "======DDPG Validation from:  2020-07-02T00:00:00.000000000 to  2020-10-01T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2020-10-01T00:00:00.000000000\n",
      "======Trading from:  2020-10-01T00:00:00.000000000 to  2020-12-31T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2020-10-01T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_252_8\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 623         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.0115     |\n",
      "|    reward             | -0.01108915 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.00162     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 631        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 0.231      |\n",
      "|    reward             | 0.10368723 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0187     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -3.29      |\n",
      "|    reward             | -0.9694101 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.355      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 637       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | -0.0352   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -53.9     |\n",
      "|    reward             | 5.2769427 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 110       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 638      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.88    |\n",
      "|    explained_variance | 0.00415  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.807    |\n",
      "|    reward             | 3.988309 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 19.6     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 639        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.87      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 0.245      |\n",
      "|    reward             | 0.11714132 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0115     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 640       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    reward             | 2.6843488 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 4.43      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 641        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -4.86      |\n",
      "|    reward             | 0.07234824 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.945      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 641        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 18.4       |\n",
      "|    reward             | -3.2970803 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 11.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 640       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -5.6      |\n",
      "|    reward             | 2.3240654 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 54.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 640       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85     |\n",
      "|    explained_variance | 0.00377   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 11.8      |\n",
      "|    reward             | 16.022243 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 53.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 639         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -2.2        |\n",
      "|    reward             | -0.29290488 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.147       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 639        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.87      |\n",
      "|    explained_variance | -0.1       |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 0.253      |\n",
      "|    reward             | 0.41210058 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.835      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 25.2       |\n",
      "|    reward             | -1.1151271 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 45.3       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -77.5      |\n",
      "|    reward             | -6.5913177 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 104        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -77.5      |\n",
      "|    reward             | -11.799218 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 195        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 636        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 72         |\n",
      "|    reward             | -13.186406 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 515        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 637         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -1.36       |\n",
      "|    reward             | -0.53507715 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.506       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 637         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | 0.038476203 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.198       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 636          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.86        |\n",
      "|    explained_variance | -0.0416      |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | 13.3         |\n",
      "|    reward             | -0.043633636 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 5.48         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 12.8     |\n",
      "|    reward             | 3.284894 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 7.14     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | -0.015     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 80.4       |\n",
      "|    reward             | -10.736356 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 376        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 637       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0.00183   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -195      |\n",
      "|    reward             | -5.217713 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.27e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -7.75      |\n",
      "|    reward             | -0.9590869 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 636       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -13.7     |\n",
      "|    reward             | 1.0645294 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 9.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.89    |\n",
      "|    explained_variance | -0.00107 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -19.5    |\n",
      "|    reward             | 3.797326 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 9.43     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 635       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -45.8     |\n",
      "|    reward             | 3.4065523 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 85.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 635       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -254      |\n",
      "|    reward             | -8.257339 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 2.27e+03  |\n",
      "-------------------------------------\n",
      "day: 2895, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11896406.18\n",
      "total_reward: 10896406.18\n",
      "total_cost: 10398.70\n",
      "total_trades: 11124\n",
      "Sharpe: 0.920\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 635        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -0.385     |\n",
      "|    reward             | 0.02011853 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.00696    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 635        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | 0.90396243 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 5.03       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 635         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 24          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | -3.29       |\n",
      "|    reward             | -0.87161684 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 3.63        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 635       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 18.6      |\n",
      "|    reward             | 0.5846858 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 8.92      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -10.4      |\n",
      "|    reward             | -4.7968297 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 5.58       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | -0.096    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 29        |\n",
      "|    reward             | 4.1774883 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 21.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 634        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | -1.21      |\n",
      "|    reward             | 0.17952989 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0713     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 634         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 11.8        |\n",
      "|    reward             | -0.81273204 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 4.3         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 634        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | -0.237     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 5.45       |\n",
      "|    reward             | 0.49150065 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.17       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 634         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | -0.89222527 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 8.67        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 633      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.88    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 8.32     |\n",
      "|    reward             | 6.812087 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 4.3      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0.0247    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -69.3     |\n",
      "|    reward             | 3.6691506 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 108       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 634          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.89        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | -2.13        |\n",
      "|    reward             | -0.029687185 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.157        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 3.19      |\n",
      "|    reward             | 0.2526766 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.562     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 25.4       |\n",
      "|    reward             | -1.3110962 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 15.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -11.2     |\n",
      "|    reward             | -3.698462 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 5.75      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -19.9     |\n",
      "|    reward             | 1.9802753 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 32.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 632       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -27.7     |\n",
      "|    reward             | 11.117549 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 24.2      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 0.478     |\n",
      "|    reward             | -0.248466 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.178     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -14.4      |\n",
      "|    reward             | 0.46039635 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 9.12       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0.00355    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | 2.7        |\n",
      "|    reward             | 0.12871072 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 4.42       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 9.64      |\n",
      "|    reward             | 1.9570075 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 9.08      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -0.00705  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -19.4     |\n",
      "|    reward             | 0.9114078 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 35.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | -63.5      |\n",
      "|    reward             | 0.94069344 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 95.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -2.77     |\n",
      "|    reward             | 0.1726355 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.332     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 8.85       |\n",
      "|    reward             | 0.20748615 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 1.67       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0.0111     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 2.88       |\n",
      "|    reward             | -1.7364166 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.772      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -35.3     |\n",
      "|    reward             | 3.4883218 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 45.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 35.8      |\n",
      "|    reward             | 11.600908 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 225       |\n",
      "-------------------------------------\n",
      "day: 2895, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9741099.78\n",
      "total_reward: 8741099.78\n",
      "total_cost: 6990.75\n",
      "total_trades: 8991\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.97       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -0.132      |\n",
      "|    reward             | 0.025185816 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.000881    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 46          |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.97       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -14.3       |\n",
      "|    reward             | -0.94395727 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 7.31        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | -0.356     |\n",
      "|    reward             | -1.2752297 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.453      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -2.07     |\n",
      "|    reward             | 2.3419564 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.8       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 634      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | 1.9      |\n",
      "|    reward             | 0.332388 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 4.92     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 1.47        |\n",
      "|    reward             | -0.14432648 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 1.27        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -0.181      |\n",
      "|    reward             | -0.26252803 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0173      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 5.11       |\n",
      "|    reward             | -0.5372734 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 633      |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.94    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | -28.2    |\n",
      "|    reward             | 1.696817 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 32.3     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 6700        |\n",
      "|    time_elapsed       | 52          |\n",
      "|    total_timesteps    | 33500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6699        |\n",
      "|    policy_loss        | 27.8        |\n",
      "|    reward             | -0.80251443 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 27.3        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 634      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.95    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 3.69     |\n",
      "|    reward             | 4.576576 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.08     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -6.8      |\n",
      "|    reward             | -2.081203 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 9.63      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 7000        |\n",
      "|    time_elapsed       | 55          |\n",
      "|    total_timesteps    | 35000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6999        |\n",
      "|    policy_loss        | -3.27       |\n",
      "|    reward             | -0.19444019 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.409       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 11.4       |\n",
      "|    reward             | 0.44024408 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 5.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -19.5     |\n",
      "|    reward             | 1.1562346 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 15.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 55.1      |\n",
      "|    reward             | 5.3143806 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 68.1      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -25.8     |\n",
      "|    reward             | 2.5105357 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 21.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -86.6      |\n",
      "|    reward             | -7.3008533 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 249        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 633         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 3.61        |\n",
      "|    reward             | -0.07996548 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.641       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 633       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 2.85      |\n",
      "|    reward             | 1.3921523 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 2.58      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | 8.14       |\n",
      "|    reward             | -0.2506776 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 2.76       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 15.2       |\n",
      "|    reward             | -0.9329041 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 17.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 634        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -25.5      |\n",
      "|    reward             | -12.648763 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 14.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 40.5      |\n",
      "|    reward             | 1.3206025 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 41.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 634        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | 8.06       |\n",
      "|    reward             | 0.10788487 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.42       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 635        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 11.2       |\n",
      "|    reward             | 0.38012362 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 2.94       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 635        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -58.1      |\n",
      "|    reward             | -0.9742082 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 101        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 635        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -5.62      |\n",
      "|    reward             | 0.33699718 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 3.13       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 635       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -38.1     |\n",
      "|    reward             | -3.953334 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 127       |\n",
      "-------------------------------------\n",
      "day: 2895, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2594416.82\n",
      "total_reward: 1594416.82\n",
      "total_cost: 1525.16\n",
      "total_trades: 6620\n",
      "Sharpe: 0.458\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 635         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 68          |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -0.351      |\n",
      "|    reward             | 0.045050357 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.00983     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 636       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 1.35      |\n",
      "|    reward             | 0.6897981 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.469     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 636       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -6.75     |\n",
      "|    reward             | 1.5399754 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.59      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 636         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | 3.69        |\n",
      "|    reward             | -0.10479138 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 636      |\n",
      "|    iterations         | 9100     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 45500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9099     |\n",
      "|    policy_loss        | 11.8     |\n",
      "|    reward             | 2.861487 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 7.07     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 637      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | -24.7    |\n",
      "|    reward             | 6.697361 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 23.2     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | 2.03       |\n",
      "|    reward             | 0.14340252 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -10.6      |\n",
      "|    reward             | -0.8372331 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 2.92       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 637       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -20.5     |\n",
      "|    reward             | 1.7505062 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 12.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 638        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 21.7       |\n",
      "|    reward             | -4.7195745 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 15         |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 638         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 75          |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -24.7       |\n",
      "|    reward             | -11.0763035 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 17.2        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 638       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -11.9     |\n",
      "|    reward             | -1.178249 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.38      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 638         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 77          |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | -0.646      |\n",
      "|    reward             | -0.31387007 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.0576      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 638       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -7.83     |\n",
      "|    reward             | -1.308394 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.76      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-10-01T00:00:00.000000000 to  2020-12-31T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.1281594903663466\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_252_8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 844        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 2          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.01698091 |\n",
      "-----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 762          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041791555 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0519       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000418    |\n",
      "|    reward               | 0.03533958   |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.139        |\n",
      "------------------------------------------\n",
      "day: 2895, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1253173.44\n",
      "total_reward: 253173.44\n",
      "total_cost: 11131.23\n",
      "total_trades: 11004\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 740            |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 8              |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.005669765    |\n",
      "|    clip_fraction        | 0.0442         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -5.66          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 0.306          |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.00285       |\n",
      "|    reward               | -0.00042840472 |\n",
      "|    std                  | 0.998          |\n",
      "|    value_loss           | 0.585          |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003719394 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0962      |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    reward               | -4.836703   |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008282674 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.45        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | -0.23335865 |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 6.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049321386 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.64        |\n",
      "|    explained_variance   | -0.00124     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 15.9         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    reward               | 0.022258503  |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 37.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002647881 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    reward               | -6.4103665  |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049541453 |\n",
      "|    clip_fraction        | 0.0438       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.93         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    reward               | -0.09043016  |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 6.71         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055949204 |\n",
      "|    clip_fraction        | 0.0403       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.35         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000473    |\n",
      "|    reward               | -0.15052228  |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 8.41         |\n",
      "------------------------------------------\n",
      "day: 2895, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2085376.01\n",
      "total_reward: 1085376.01\n",
      "total_cost: 11771.49\n",
      "total_trades: 10800\n",
      "Sharpe: 0.482\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00374698  |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    reward               | -0.07470976 |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006237277 |\n",
      "|    clip_fraction        | 0.0618      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | -6.4498773  |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037022044 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.889        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -5.05e-05    |\n",
      "|    reward               | 0.36269736   |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 4.55         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005960888 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | -0.02       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 0.16739503  |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 66.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054337233 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 0.0806       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 93.4         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    reward               | -4.9593825   |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 177          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053129843 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | -0.0158      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000337    |\n",
      "|    reward               | 0.23856224   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 73.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009306176  |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00748     |\n",
      "|    reward               | -0.037187655 |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "day: 2895, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 7563015.13\n",
      "total_reward: 6563015.13\n",
      "total_cost: 11646.94\n",
      "total_trades: 10900\n",
      "Sharpe: 0.772\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075646797 |\n",
      "|    clip_fraction        | 0.0551       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 48.2         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    reward               | -0.018258365 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 207          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005576685 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 415         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    reward               | 0.9637888   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 453         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005799085 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.00041     |\n",
      "|    reward               | 0.2666792   |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030706415 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 174          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    reward               | -0.09502743  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 397          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050648423 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 258          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | 11.986766    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 277          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063684382 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    reward               | -0.6496231   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 97.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025366677 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 252          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    reward               | -0.1861649   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058755465 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.054        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 82.1         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    reward               | 5.8042345    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 259          |\n",
      "------------------------------------------\n",
      "day: 2895, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4950433.43\n",
      "total_reward: 3950433.43\n",
      "total_cost: 11237.97\n",
      "total_trades: 10579\n",
      "Sharpe: 0.659\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058559217 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0798       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 161          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    reward               | -0.4885558   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2020-10-01T00:00:00.000000000 to  2020-12-31T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.11981697593120026\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_8\n",
      "day: 2895, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2743651.39\n",
      "total_reward: 1743651.39\n",
      "total_cost: 999.00\n",
      "total_trades: 2895\n",
      "Sharpe: 0.474\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 427         |\n",
      "|    time_elapsed    | 27          |\n",
      "|    total_timesteps | 11584       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -1.14e+03   |\n",
      "|    critic_loss     | 1.21e+04    |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 8688        |\n",
      "|    reward          | -0.26330566 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 389         |\n",
      "|    time_elapsed    | 59          |\n",
      "|    total_timesteps | 23168       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -659        |\n",
      "|    critic_loss     | 243         |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 20272       |\n",
      "|    reward          | -0.26330566 |\n",
      "------------------------------------\n",
      "day: 2895, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2743651.39\n",
      "total_reward: 1743651.39\n",
      "total_cost: 999.00\n",
      "total_trades: 2895\n",
      "Sharpe: 0.474\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 378         |\n",
      "|    time_elapsed    | 91          |\n",
      "|    total_timesteps | 34752       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -361        |\n",
      "|    critic_loss     | 32.3        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 31856       |\n",
      "|    reward          | -0.26330566 |\n",
      "------------------------------------\n",
      "day: 2895, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2743651.39\n",
      "total_reward: 1743651.39\n",
      "total_cost: 999.00\n",
      "total_trades: 2895\n",
      "Sharpe: 0.474\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 370         |\n",
      "|    time_elapsed    | 124         |\n",
      "|    total_timesteps | 46336       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -195        |\n",
      "|    critic_loss     | 14.1        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 43440       |\n",
      "|    reward          | -0.26330566 |\n",
      "------------------------------------\n",
      "======DDPG Validation from:  2020-10-01T00:00:00.000000000 to  2020-12-31T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2020-12-31T00:00:00.000000000\n",
      "======Trading from:  2020-12-31T00:00:00.000000000 to  2021-04-05T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2020-12-31T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_315_8\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 619         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.552      |\n",
      "|    reward             | -0.15826675 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.0152      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 628        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -0.168     |\n",
      "|    reward             | 0.04430235 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.00117    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -2.53      |\n",
      "|    reward             | 0.25026172 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.263      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 635       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 0.529     |\n",
      "|    reward             | 1.0642625 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.136     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 637        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -1.81      |\n",
      "|    reward             | 0.25300488 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 639          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.9         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.883       |\n",
      "|    reward             | 0.0029470252 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.0125       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 640         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -0.874      |\n",
      "|    reward             | -0.04722582 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0517      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 641        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 2.16       |\n",
      "|    reward             | 0.03136932 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 643        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 1.2        |\n",
      "|    reward             | -2.2402651 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.23       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 11.5      |\n",
      "|    reward             | 6.1368566 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 14        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0.0516     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 2.04       |\n",
      "|    reward             | -7.3561482 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.2        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 645          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.93        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | -0.324       |\n",
      "|    reward             | -0.042687487 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 0.00307      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 646       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -2.73     |\n",
      "|    reward             | 0.3199212 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.319     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 647       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 1.44      |\n",
      "|    reward             | 1.8419244 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.545     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 649        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.95      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -45.5      |\n",
      "|    reward             | -1.7825866 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 52.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 649       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -30.1     |\n",
      "|    reward             | 7.9791155 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 72.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 650        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0.00989    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 82.6       |\n",
      "|    reward             | -1.5608064 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 362        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -0.739      |\n",
      "|    reward             | -0.17160718 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0178      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 8.52       |\n",
      "|    reward             | -2.9510689 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.96       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 38.7       |\n",
      "|    reward             | 0.92342424 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 41.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | -68.9     |\n",
      "|    reward             | -3.038268 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 121       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -10.2    |\n",
      "|    reward             | 8.7707   |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 36.3     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | -0.00131   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | 40.5       |\n",
      "|    reward             | -17.793434 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 255        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 656          |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.98        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.427        |\n",
      "|    reward             | -0.015065916 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00566      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 656          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.98        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -4.97        |\n",
      "|    reward             | -0.099898644 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 1            |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -0.183    |\n",
      "|    reward             | 1.0246029 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.0604    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 76.9       |\n",
      "|    reward             | -1.8961414 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 153        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0.00303   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -3.75     |\n",
      "|    reward             | 6.8373632 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 35.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -188      |\n",
      "|    reward             | -36.18894 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.61e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2958, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 22572078.29\n",
      "total_reward: 21572078.29\n",
      "total_cost: 11659.47\n",
      "total_trades: 8896\n",
      "Sharpe: 0.948\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -2.67      |\n",
      "|    reward             | -0.2078431 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.217      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 15.6        |\n",
      "|    reward             | -0.62504035 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 8.95        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 69.5      |\n",
      "|    reward             | 5.2542243 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 134       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -22.3      |\n",
      "|    reward             | -3.0511951 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 17         |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6       |\n",
      "|    explained_variance | -0.001   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -35.7    |\n",
      "|    reward             | 66.0755  |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 64.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 26         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | -0.000175  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 414        |\n",
      "|    reward             | -29.295048 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 6.76e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 27          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | -0.638      |\n",
      "|    reward             | -0.46135834 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.052       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 658         |\n",
      "|    iterations         | 3700        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 18500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.02       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3699        |\n",
      "|    policy_loss        | 4.49        |\n",
      "|    reward             | -0.18252935 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 658         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 28          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -6.12       |\n",
      "|    reward             | -0.44088385 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 5.81        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.03      |\n",
      "|    explained_variance | -0.00532   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 10.4       |\n",
      "|    reward             | -1.1177303 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 9          |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -124     |\n",
      "|    reward             | 8.237648 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 764      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 658      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.03    |\n",
      "|    explained_variance | 0.00037  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -11.3    |\n",
      "|    reward             | 39.02277 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.83e+03 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 657           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.03         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -2.62         |\n",
      "|    reward             | -0.0008487634 |\n",
      "|    std                | 1.09          |\n",
      "|    value_loss         | 0.23          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 32          |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.04       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -3.65       |\n",
      "|    reward             | -0.83013326 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.713       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 4400        |\n",
      "|    time_elapsed       | 33          |\n",
      "|    total_timesteps    | 22000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4399        |\n",
      "|    policy_loss        | -26.4       |\n",
      "|    reward             | -0.17290762 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 21.3        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | -0.00797   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -30.1      |\n",
      "|    reward             | 0.99291354 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 29.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | -0.000251  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -284       |\n",
      "|    reward             | -2.7907925 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 1.6e+03    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.04      |\n",
      "|    explained_variance | -8.43e-05  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | 30.2       |\n",
      "|    reward             | -33.234974 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 1.4e+03    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -0.213      |\n",
      "|    reward             | -0.59761614 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.0853      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 12.4      |\n",
      "|    reward             | 0.8809447 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 9.04      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.07     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 25        |\n",
      "|    reward             | 3.7488582 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 31.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 8.92     |\n",
      "|    reward             | 5.555072 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 29.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 39         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0.000295   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | -324       |\n",
      "|    reward             | -13.779314 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.32e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 2.84      |\n",
      "|    reward             | 29.887854 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 340       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.07      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | 8.32       |\n",
      "|    reward             | 0.38414547 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.86       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -6.54     |\n",
      "|    reward             | 0.2897731 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 3.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -8.69      |\n",
      "|    reward             | -6.3636065 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 25         |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 43         |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.11      |\n",
      "|    explained_variance | -0.00117   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -86.9      |\n",
      "|    reward             | -0.5981443 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 260        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 70.3      |\n",
      "|    reward             | 30.369104 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 193       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.11     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 216       |\n",
      "|    reward             | 1.5685923 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.64e+03  |\n",
      "-------------------------------------\n",
      "day: 2958, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 19786244.09\n",
      "total_reward: 18786244.09\n",
      "total_cost: 11281.95\n",
      "total_trades: 10578\n",
      "Sharpe: 0.800\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 6.22       |\n",
      "|    reward             | 0.98988837 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.903      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.14     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -11.9     |\n",
      "|    reward             | 0.8984367 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 6.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 43.4       |\n",
      "|    reward             | -15.371547 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 82.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 20.7      |\n",
      "|    reward             | 0.9285755 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 14.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -175      |\n",
      "|    reward             | 34.680023 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.11e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.15      |\n",
      "|    explained_variance | -0.0331    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -266       |\n",
      "|    reward             | -36.463688 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 2.03e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 50          |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.18       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.598      |\n",
      "|    reward             | -0.07242103 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.035       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 12.4       |\n",
      "|    reward             | 0.19297422 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 4.64       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 60.7      |\n",
      "|    reward             | -6.521685 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 172       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -12.2      |\n",
      "|    reward             | -1.9280257 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 10.4       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.2      |\n",
      "|    explained_variance | 0.000703  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -77.8     |\n",
      "|    reward             | 29.770988 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 301       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.21     |\n",
      "|    explained_variance | 0.000574  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -177      |\n",
      "|    reward             | 7.8687305 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.08e+03  |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 656          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 54           |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.23        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.909       |\n",
      "|    reward             | -0.009605032 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.0259       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 1.24       |\n",
      "|    reward             | -0.9629066 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.123      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -14.7     |\n",
      "|    reward             | 2.2329173 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 5.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.25     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 36.7      |\n",
      "|    reward             | 2.2686126 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 40.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.26     |\n",
      "|    explained_variance | -0.00357  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -47.6     |\n",
      "|    reward             | 1.1941273 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 63.5      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.24       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -1.76       |\n",
      "|    reward             | 0.007559928 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 7800        |\n",
      "|    time_elapsed       | 59          |\n",
      "|    total_timesteps    | 39000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.26       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7799        |\n",
      "|    policy_loss        | -4.24       |\n",
      "|    reward             | -0.43482924 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.713       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 7900        |\n",
      "|    time_elapsed       | 60          |\n",
      "|    total_timesteps    | 39500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7899        |\n",
      "|    policy_loss        | 5.53        |\n",
      "|    reward             | 0.062317714 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -11.1      |\n",
      "|    reward             | -2.1074743 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 4.83       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 3.08        |\n",
      "|    reward             | -0.54441243 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 1.45        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.29      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -21.2      |\n",
      "|    reward             | -1.2838764 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 15.2       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 63          |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.29       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | -0.635      |\n",
      "|    reward             | 0.002784676 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 656          |\n",
      "|    iterations         | 8400         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 42000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.35        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 8399         |\n",
      "|    policy_loss        | 0.0715       |\n",
      "|    reward             | -0.009133769 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.000175     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 656          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 64           |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.41        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | 0.066        |\n",
      "|    reward             | 0.0007127369 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 656           |\n",
      "|    iterations         | 8600          |\n",
      "|    time_elapsed       | 65            |\n",
      "|    total_timesteps    | 43000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.52         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 8599          |\n",
      "|    policy_loss        | 0.052         |\n",
      "|    reward             | -0.0009999069 |\n",
      "|    std                | 1.24          |\n",
      "|    value_loss         | 0.0003        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.58     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 1.39      |\n",
      "|    reward             | -1.026009 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.123     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.6      |\n",
      "|    explained_variance | -0.242    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -4.54     |\n",
      "|    reward             | 0.5304956 |\n",
      "|    std                | 1.26      |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "day: 2958, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2461194.77\n",
      "total_reward: 1461194.77\n",
      "total_cost: 10168.75\n",
      "total_trades: 9069\n",
      "Sharpe: 0.490\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 655         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.6        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 1           |\n",
      "|    reward             | -0.01471889 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 0.0277      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.61      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 5.03       |\n",
      "|    reward             | -0.2991566 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.61      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | -6.9       |\n",
      "|    reward             | 0.35032743 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 1.9        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.6       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -47.8      |\n",
      "|    reward             | -1.6066871 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 70.6       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 655         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 70          |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.61       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | -29.9       |\n",
      "|    reward             | -0.33334026 |\n",
      "|    std                | 1.26        |\n",
      "|    value_loss         | 107         |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | -45.1    |\n",
      "|    reward             | 6.071064 |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 92.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.61      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | 0.246      |\n",
      "|    reward             | 0.06838831 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 0.0745     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.62      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 1.15       |\n",
      "|    reward             | 0.09050726 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 0.176      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.61      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -45.1      |\n",
      "|    reward             | 0.13036774 |\n",
      "|    std                | 1.26       |\n",
      "|    value_loss         | 61.6       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 49000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | -13.2    |\n",
      "|    reward             | 0.941964 |\n",
      "|    std                | 1.27     |\n",
      "|    value_loss         | 3.1      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.63      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 116        |\n",
      "|    reward             | -2.3888204 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 307        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.62      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 69.5       |\n",
      "|    reward             | -10.396666 |\n",
      "|    std                | 1.27       |\n",
      "|    value_loss         | 134        |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2020-12-31T00:00:00.000000000 to  2021-04-05T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.038972733903454584\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_315_8\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 835        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 2          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | -0.1989541 |\n",
      "-----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 759          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070005143 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0145       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.009407266 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.202        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061329324 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.65         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | 0.0034204763 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 6            |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 726          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042687906 |\n",
      "|    clip_fraction        | 0.041        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.24         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.38645583  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.665        |\n",
      "------------------------------------------\n",
      "day: 2958, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1719792.99\n",
      "total_reward: 719792.99\n",
      "total_cost: 12106.11\n",
      "total_trades: 11285\n",
      "Sharpe: 0.624\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037470618 |\n",
      "|    clip_fraction        | 0.045        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0304       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    reward               | -0.006441193 |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 0.324        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006791956 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.65       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    reward               | 0.027403336 |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 4.32        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060101813 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.214        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    reward               | 0.085068814  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.694        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051628742 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0333       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    reward               | -0.020140007 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.198        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067571187 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.322        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | -0.001961636 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 1.09         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048334547 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.116        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    reward               | 0.14337571   |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040330356 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.64        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0616       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 0.032905053  |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 0.155        |\n",
      "------------------------------------------\n",
      "day: 2958, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1333311.42\n",
      "total_reward: 333311.42\n",
      "total_cost: 11753.80\n",
      "total_trades: 10528\n",
      "Sharpe: 0.542\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072389026 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.65        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.011       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 0.020342983  |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.0868       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058254367 |\n",
      "|    clip_fraction        | 0.0523       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.673        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    reward               | 1.819158     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 1.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005335824  |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.66        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.38         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    reward               | -0.015674436 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 14           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046629957 |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0328       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.10703431   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.238        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066189715 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.31         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    reward               | 0.014623147  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 7.31         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 695         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004635918 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | -0.00142    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    reward               | 0.88144666  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 57.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039750454 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.47         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0003      |\n",
      "|    reward               | 0.90967435   |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 15.3         |\n",
      "------------------------------------------\n",
      "day: 2958, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6475417.59\n",
      "total_reward: 5475417.59\n",
      "total_cost: 12490.73\n",
      "total_trades: 11017\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 695        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00437463 |\n",
      "|    clip_fraction        | 0.0154     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.66      |\n",
      "|    explained_variance   | 0.0417     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 33.1       |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.00287   |\n",
      "|    reward               | 0.22441946 |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 156        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062828525 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    reward               | 5.531918     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007717614 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | -0.00963    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | -0.3223134  |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 55.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038627414 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    reward               | 0.24212182   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 116          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014317726 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 177          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    reward               | -3.6215975   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 215          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037407156 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | -0.34546632  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 94.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003910609 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -0.15121484 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-12-31T00:00:00.000000000 to  2021-04-05T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.021580902637182712\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_8\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 430       |\n",
      "|    time_elapsed    | 27        |\n",
      "|    total_timesteps | 11836     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -5.36e+03 |\n",
      "|    critic_loss     | 2.23e+04  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 8877      |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 2958, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 389       |\n",
      "|    time_elapsed    | 60        |\n",
      "|    total_timesteps | 23672     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.04e+03 |\n",
      "|    critic_loss     | 6.85e+03  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 20713     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 2958, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 375       |\n",
      "|    time_elapsed    | 94        |\n",
      "|    total_timesteps | 35508     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.13e+03 |\n",
      "|    critic_loss     | 2.1e+03   |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 32549     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 2958, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 370       |\n",
      "|    time_elapsed    | 127       |\n",
      "|    total_timesteps | 47344     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.13e+03 |\n",
      "|    critic_loss     | 593       |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 44385     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2020-12-31T00:00:00.000000000 to  2021-04-05T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2021-04-05T00:00:00.000000000\n",
      "======Trading from:  2021-04-05T00:00:00.000000000 to  2021-07-02T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2021-04-05T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_378_8\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 646          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.86        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -0.0756      |\n",
      "|    reward             | -0.031995337 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.000478     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 654           |\n",
      "|    iterations         | 200           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 1000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 199           |\n",
      "|    policy_loss        | -0.105        |\n",
      "|    reward             | 0.00078214175 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.000369      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 1.02       |\n",
      "|    reward             | -0.3428344 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.243      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -1.69      |\n",
      "|    reward             | -0.5075372 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.569      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.04     |\n",
      "|    explained_variance | -0.00452  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -14.2     |\n",
      "|    reward             | 3.2291617 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 54.8      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -147       |\n",
      "|    reward             | -36.419373 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 862        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -3.94       |\n",
      "|    reward             | -0.34658554 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.283       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -0.549     |\n",
      "|    reward             | -1.7942269 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.0781     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.08      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 3.14       |\n",
      "|    reward             | -1.7850381 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 1.47       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 659          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.07        |\n",
      "|    explained_variance | -0.000252    |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 30.6         |\n",
      "|    reward             | 0.0003407859 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 37.9         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 659        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | 0.0275     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 230        |\n",
      "|    reward             | -9.6428175 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 1.37e+03   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | -0.00385   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 52.9       |\n",
      "|    reward             | -14.813981 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 212        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.07      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 0.758      |\n",
      "|    reward             | 0.01297658 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.0979     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 9.6        |\n",
      "|    reward             | -0.3846162 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 2.46       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 658       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.06     |\n",
      "|    explained_variance | -0.0303   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -70.8     |\n",
      "|    reward             | 2.4077075 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 153       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -12.2      |\n",
      "|    reward             | -0.6124004 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 9.65       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.06     |\n",
      "|    explained_variance | -0.000247 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -35.2     |\n",
      "|    reward             | -17.32965 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.5e+03   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | 0.00258    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 323        |\n",
      "|    reward             | -30.293205 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 3.26e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -0.846     |\n",
      "|    reward             | 0.43232793 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.0618     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 655         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 3.4         |\n",
      "|    reward             | -0.83844876 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.472       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 19.6       |\n",
      "|    reward             | -2.6087058 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 18.5       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 655         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.13       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 4.09        |\n",
      "|    reward             | -0.52727175 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 8.87        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.13     |\n",
      "|    explained_variance | -0.000154 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -75.7     |\n",
      "|    reward             | -3.820716 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 372       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.13      |\n",
      "|    explained_variance | 0.00246    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | -237       |\n",
      "|    reward             | -24.001799 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 1.97e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 654         |\n",
      "|    iterations         | 2500        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 12500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.16       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2499        |\n",
      "|    policy_loss        | -0.868      |\n",
      "|    reward             | 0.029467834 |\n",
      "|    std                | 1.13        |\n",
      "|    value_loss         | 0.0575      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.17      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -0.0138    |\n",
      "|    reward             | 0.04500803 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 0.933      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.18     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -12.7     |\n",
      "|    reward             | -4.264043 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 29.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -179     |\n",
      "|    reward             | -0.95489 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 697      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -138       |\n",
      "|    reward             | -28.366358 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 844        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -123      |\n",
      "|    reward             | 22.925463 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 694       |\n",
      "-------------------------------------\n",
      "day: 3021, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 11645881.44\n",
      "total_reward: 10645881.44\n",
      "total_cost: 4971.12\n",
      "total_trades: 7204\n",
      "Sharpe: 0.656\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 11.3      |\n",
      "|    reward             | 0.1490088 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 5.91      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.2     |\n",
      "|    explained_variance | 0.00734  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 11.2     |\n",
      "|    reward             | 2.920093 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 3.93     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -47.9     |\n",
      "|    reward             | 16.112844 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 71.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -100      |\n",
      "|    reward             | 3.4723055 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 349       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | -0.000836 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 24.9      |\n",
      "|    reward             | -30.9835  |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 411       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.18     |\n",
      "|    explained_variance | -0.00345  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 3.89      |\n",
      "|    reward             | 17.615543 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 217       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 0.6896141 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 5.22      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -11.8      |\n",
      "|    reward             | 0.33353543 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 5.37       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 652      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -36.9    |\n",
      "|    reward             | 4.723068 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 90.3     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.2      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -131      |\n",
      "|    reward             | -5.719744 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 408       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 13.2      |\n",
      "|    reward             | 20.510101 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 50.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | -36.4      |\n",
      "|    reward             | -21.257675 |\n",
      "|    std                | 1.13       |\n",
      "|    value_loss         | 359        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.18     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -0.429    |\n",
      "|    reward             | 0.2072102 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 0.016     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0.00145    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -7.58      |\n",
      "|    reward             | -2.0072296 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 2.99       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.2      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 2.39      |\n",
      "|    reward             | 1.1320764 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 37.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 23000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -8.57    |\n",
      "|    reward             | 9.263335 |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 11       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.21     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 197       |\n",
      "|    reward             | -8.507652 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 1.13e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0.00469    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | 299        |\n",
      "|    reward             | -7.2457604 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 2.53e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.21       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 0.358       |\n",
      "|    reward             | -0.25304145 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.21       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | 14.4        |\n",
      "|    reward             | -0.78499913 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 7.01        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.23     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -12.5     |\n",
      "|    reward             | -9.052251 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 13.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.22     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -15.1     |\n",
      "|    reward             | 1.1161098 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 81.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.22      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 198        |\n",
      "|    reward             | -30.506004 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 1.45e+03   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.22     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -278      |\n",
      "|    reward             | 47.61912  |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.83e+03  |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 652           |\n",
      "|    iterations         | 5500          |\n",
      "|    time_elapsed       | 42            |\n",
      "|    total_timesteps    | 27500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.24         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 5499          |\n",
      "|    policy_loss        | -2.95         |\n",
      "|    reward             | 0.00025905934 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 0.322         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 652         |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 42          |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -12.2       |\n",
      "|    reward             | -0.57982796 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 4.28        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.23     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 65.6      |\n",
      "|    reward             | 10.268879 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 88.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.22     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 3.52      |\n",
      "|    reward             | 6.9694314 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.08      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -49.3      |\n",
      "|    reward             | -22.390842 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 157        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.22     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 191       |\n",
      "|    reward             | -9.428962 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 2.23e+03  |\n",
      "-------------------------------------\n",
      "day: 3021, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 18110522.38\n",
      "total_reward: 17110522.38\n",
      "total_cost: 3909.39\n",
      "total_trades: 9497\n",
      "Sharpe: 0.723\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.24      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -1.25      |\n",
      "|    reward             | 0.22145195 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.0648     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 18.8       |\n",
      "|    reward             | -0.4399377 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 13         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -19.7     |\n",
      "|    reward             | -4.724629 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 19.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 2.92       |\n",
      "|    reward             | 0.88588434 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 2.95       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 148       |\n",
      "|    reward             | 13.039575 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 972       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 378       |\n",
      "|    reward             | 35.686043 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 6.14e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 1.88       |\n",
      "|    reward             | 0.08450062 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.26      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 10.5       |\n",
      "|    reward             | -1.9251381 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 4.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -20.2      |\n",
      "|    reward             | 0.67362875 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 32.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 7.59       |\n",
      "|    reward             | 0.25093377 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 2.91       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 0.00039    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 84.8       |\n",
      "|    reward             | 0.13700686 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 405        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.26      |\n",
      "|    explained_variance | 0.000968   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -269       |\n",
      "|    reward             | 0.91382426 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 3.89e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.27     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.25      |\n",
      "|    reward             | 0.6669493 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.102     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 652         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 56          |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | 4.69        |\n",
      "|    reward             | -0.50529623 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 2.11        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 68.3       |\n",
      "|    reward             | -6.4914103 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 133        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 652      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.22    |\n",
      "|    explained_variance | -0.0202  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 55.4     |\n",
      "|    reward             | -4.62813 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 101      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -71        |\n",
      "|    reward             | -6.0267315 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 638        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 48.4     |\n",
      "|    reward             | -13.8757 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 509      |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 653          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 60           |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.21        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -3.27        |\n",
      "|    reward             | -0.029712882 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.384        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -0.52     |\n",
      "|    reward             | 1.6803231 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 2.96      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 653         |\n",
      "|    iterations         | 8100        |\n",
      "|    time_elapsed       | 61          |\n",
      "|    total_timesteps    | 40500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.21       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8099        |\n",
      "|    policy_loss        | 12.8        |\n",
      "|    reward             | -0.63376516 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 11.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 8200       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 41000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.22      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8199       |\n",
      "|    policy_loss        | -33.6      |\n",
      "|    reward             | 0.37418008 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 85.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -65.3     |\n",
      "|    reward             | -52.62734 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.09e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | 2.98e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 381        |\n",
      "|    reward             | -160.25421 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 4.63e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 1.55       |\n",
      "|    reward             | 0.68000954 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 0.137      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 7.15       |\n",
      "|    reward             | -1.2112613 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 2.02       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -17.1     |\n",
      "|    reward             | 1.7339818 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 9.83      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -8.18      |\n",
      "|    reward             | -0.3302943 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 5.37       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -250      |\n",
      "|    reward             | 15.264943 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 2.15e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 108       |\n",
      "|    reward             | 13.387338 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 285       |\n",
      "-------------------------------------\n",
      "day: 3021, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 18339823.58\n",
      "total_reward: 17339823.58\n",
      "total_cost: 3803.60\n",
      "total_trades: 9108\n",
      "Sharpe: 0.773\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 654           |\n",
      "|    iterations         | 9100          |\n",
      "|    time_elapsed       | 69            |\n",
      "|    total_timesteps    | 45500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.24         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 9099          |\n",
      "|    policy_loss        | -0.919        |\n",
      "|    reward             | -0.0058153393 |\n",
      "|    std                | 1.15          |\n",
      "|    value_loss         | 0.0536        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -22        |\n",
      "|    reward             | -1.3533536 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 9.81       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 3.1       |\n",
      "|    reward             | 5.238259  |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 17        |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 654         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.25       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 13.7        |\n",
      "|    reward             | -0.04251607 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 6.94        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 289       |\n",
      "|    reward             | 29.694923 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.09e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -196      |\n",
      "|    reward             | -9.809512 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 2.29e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.24      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -1.71      |\n",
      "|    reward             | -0.1337136 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.0532     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.26     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -9.14     |\n",
      "|    reward             | -3.228891 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 3.66      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 4.13      |\n",
      "|    reward             | 2.5836654 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 5.15      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.23     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -245      |\n",
      "|    reward             | 6.6433296 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 4.09e+03  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2021-04-05T00:00:00.000000000 to  2021-07-02T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.3993877133401611\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_378_8\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 839         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 2           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.10724908 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 746          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061809076 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.00248      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    reward               | -0.09125684  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0873       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006723714 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 1.07e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | -0.00482689 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.85        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032664607 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.00337      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.42         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    reward               | 0.13980854   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 38.7         |\n",
      "------------------------------------------\n",
      "day: 3021, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1216776.17\n",
      "total_reward: 216776.17\n",
      "total_cost: 12721.60\n",
      "total_trades: 11492\n",
      "Sharpe: 0.744\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 714          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045362227 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0419      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000933    |\n",
      "|    reward               | 0.009838263  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 0.0428       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051730126 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0763       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    reward               | -0.013781292 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.234        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 705        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00464793 |\n",
      "|    clip_fraction        | 0.0167     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.7       |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.25       |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.000822  |\n",
      "|    reward               | 0.09951512 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.23       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006331444 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | 0.02618185  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042535877 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 6.92         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    reward               | 0.084285036  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 13.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005416835 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 4.39e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    reward               | -4.2054825  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 696        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00701393 |\n",
      "|    clip_fraction        | 0.0591     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.62       |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00303   |\n",
      "|    reward               | 0.08016073 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 5.81       |\n",
      "----------------------------------------\n",
      "day: 3021, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3065061.85\n",
      "total_reward: 2065061.85\n",
      "total_cost: 13242.93\n",
      "total_trades: 11017\n",
      "Sharpe: 0.690\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 696            |\n",
      "|    iterations           | 12             |\n",
      "|    time_elapsed         | 35             |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0050380146   |\n",
      "|    clip_fraction        | 0.031          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -5.72          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.00025        |\n",
      "|    loss                 | 44.7           |\n",
      "|    n_updates            | 110            |\n",
      "|    policy_gradient_loss | -0.00255       |\n",
      "|    reward               | -7.3010786e-05 |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 71.7           |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058299033 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.6         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    reward               | -3.9579487   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 34.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050259307 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.77         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    reward               | -0.66963154  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 12.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048215147 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 12.9         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    reward               | 0.017792527  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004970884 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    reward               | 1.9680628   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 43.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004570822  |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    reward               | -0.013971248 |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 7.56         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005886094  |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.21         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    reward               | -0.033990238 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 13           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008304619 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.00912     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    reward               | -3.491371   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 79.4        |\n",
      "-----------------------------------------\n",
      "day: 3021, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3325270.71\n",
      "total_reward: 2325270.71\n",
      "total_cost: 13655.20\n",
      "total_trades: 11404\n",
      "Sharpe: 0.677\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071049253 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 10.7         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    reward               | 0.08522777   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 12.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009474579  |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | 0.0097486265 |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 36.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052402713 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -2.4151182   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 44.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067160353 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.519        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    reward               | -0.07207454  |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 2.02         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00445522  |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.84       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.06        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    reward               | -0.04340603 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 4.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004626492 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.86       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | 2.028212    |\n",
      "|    std                  | 1.05        |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======PPO Validation from:  2021-04-05T00:00:00.000000000 to  2021-07-02T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.515511027390828\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_8\n",
      "day: 3021, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1479989.48\n",
      "total_reward: 479989.48\n",
      "total_cost: 1342.68\n",
      "total_trades: 4400\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 417      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 12088    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -267     |\n",
      "|    critic_loss     | 9.89e+03 |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 9066     |\n",
      "|    reward          | 8.962396 |\n",
      "---------------------------------\n",
      "day: 3021, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 14284240.82\n",
      "total_reward: 13284240.82\n",
      "total_cost: 999.00\n",
      "total_trades: 6042\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 382      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 24176    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -250     |\n",
      "|    critic_loss     | 451      |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 21154    |\n",
      "|    reward          | 8.962396 |\n",
      "---------------------------------\n",
      "day: 3021, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 14284240.82\n",
      "total_reward: 13284240.82\n",
      "total_cost: 999.00\n",
      "total_trades: 6042\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 370      |\n",
      "|    time_elapsed    | 97       |\n",
      "|    total_timesteps | 36264    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -153     |\n",
      "|    critic_loss     | 372      |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 33242    |\n",
      "|    reward          | 8.962396 |\n",
      "---------------------------------\n",
      "day: 3021, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 14284240.82\n",
      "total_reward: 13284240.82\n",
      "total_cost: 999.00\n",
      "total_trades: 6042\n",
      "Sharpe: 0.706\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 366      |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 48352    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 360      |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 45330    |\n",
      "|    reward          | 8.962396 |\n",
      "---------------------------------\n",
      "======DDPG Validation from:  2021-04-05T00:00:00.000000000 to  2021-07-02T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2021-07-02T00:00:00.000000000\n",
      "======Trading from:  2021-07-02T00:00:00.000000000 to  2021-10-01T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2021-07-02T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_441_8\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 647         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 0           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -1.79       |\n",
      "|    reward             | 0.097770885 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.285       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.77      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | 3.28       |\n",
      "|    reward             | 0.45109606 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.594      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.79      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -14.6      |\n",
      "|    reward             | 0.12772785 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 8.07       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.8      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -29.3     |\n",
      "|    reward             | 3.9908905 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 31.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 656      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.8     |\n",
      "|    explained_variance | -0.137   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 7.17     |\n",
      "|    reward             | 2.108616 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.8      |\n",
      "|    explained_variance | 0.00238   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -68.3     |\n",
      "|    reward             | -34.04961 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 563       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 655          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.83        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -2.06        |\n",
      "|    reward             | -0.100772925 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.291        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -4.2       |\n",
      "|    reward             | 0.36471388 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.79       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 657         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -5.73       |\n",
      "|    reward             | -0.15589567 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 1.22        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85     |\n",
      "|    explained_variance | 0.111     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -10       |\n",
      "|    reward             | 3.6415396 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 5.81      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.86    |\n",
      "|    explained_variance | -0.0399  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -2.95    |\n",
      "|    reward             | 4.167886 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 11.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.87      |\n",
      "|    explained_variance | -0.047     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -25.2      |\n",
      "|    reward             | -7.2441077 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 40.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 658         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -1.94       |\n",
      "|    reward             | 0.031295184 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.0972      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 658        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -4.62      |\n",
      "|    reward             | 0.07115999 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.73       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 658       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -25.7     |\n",
      "|    reward             | 3.4750712 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 25.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 658       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | -0.0183   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 26.2      |\n",
      "|    reward             | 1.7082134 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 22.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 658       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | -0.0232   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -83.4     |\n",
      "|    reward             | 3.4149652 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 252       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 657       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89     |\n",
      "|    explained_variance | -0.000263 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 27.5      |\n",
      "|    reward             | 17.942535 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 59.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -1.52      |\n",
      "|    reward             | 0.03507757 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.0781     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -0.373     |\n",
      "|    reward             | 0.29273888 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.689      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -12.7      |\n",
      "|    reward             | -2.4739597 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 5.49       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | -0.04      |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | -9.94      |\n",
      "|    reward             | -2.6629477 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 6.43       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 657      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -103     |\n",
      "|    reward             | 7.767521 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 276      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2400       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 12000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2399       |\n",
      "|    policy_loss        | 80.5       |\n",
      "|    reward             | -3.1506133 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 325        |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 657          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.92        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | 0.756        |\n",
      "|    reward             | -0.095752776 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.0238       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | 1.81       |\n",
      "|    reward             | 0.26702955 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.42       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 657        |\n",
      "|    iterations         | 2700       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 13500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2699       |\n",
      "|    policy_loss        | 8.41       |\n",
      "|    reward             | -2.1676853 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 2800        |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 14000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2799        |\n",
      "|    policy_loss        | 0.55        |\n",
      "|    reward             | 0.108964905 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 1.18        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0.0229    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 82.2      |\n",
      "|    reward             | 12.671944 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 210       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | -0.0511   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 83.5      |\n",
      "|    reward             | 10.341163 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 828       |\n",
      "-------------------------------------\n",
      "day: 3084, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 9541326.04\n",
      "total_reward: 8541326.04\n",
      "total_cost: 14390.31\n",
      "total_trades: 11597\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 23          |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 0.0401      |\n",
      "|    reward             | 0.031526223 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 0.00196     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | 8.75       |\n",
      "|    reward             | 0.22840908 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 2          |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 9.22      |\n",
      "|    reward             | 2.6151931 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 25          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | -2.06e-05   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -21.5       |\n",
      "|    reward             | -0.35764775 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 44.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 114       |\n",
      "|    reward             | 19.885513 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 292       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0.00828    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | 172        |\n",
      "|    reward             | -15.948229 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.05e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0.00262    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 267        |\n",
      "|    reward             | -3.7886662 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 3.31e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | -1.94      |\n",
      "|    reward             | 0.17836748 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.321      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 29         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -0.0966    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 31.6       |\n",
      "|    reward             | 0.18520704 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 20.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | -32.3     |\n",
      "|    reward             | 6.9398694 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 144       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 656      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 20500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.94    |\n",
      "|    explained_variance | 0.00504  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 33.6     |\n",
      "|    reward             | 8.601358 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 45.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | 0.00178   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 26.2      |\n",
      "|    reward             | 59.340294 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 149       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | -0.00308  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 443       |\n",
      "|    reward             | -94.33275 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 7.69e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -51        |\n",
      "|    reward             | -0.5158343 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 53.4       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 656         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -32.8       |\n",
      "|    reward             | -0.36228633 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 44.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -0.000431  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | -3.2885835 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 17.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 656       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0.0276    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 28.6      |\n",
      "|    reward             | 3.0901158 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 90.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 4800       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 24000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -0.000567  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4799       |\n",
      "|    policy_loss        | -230       |\n",
      "|    reward             | -26.202536 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.94e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | -0.00509   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | 297        |\n",
      "|    reward             | -33.308994 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.98e+03   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 656        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 38         |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | -12.6      |\n",
      "|    reward             | -0.7738252 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 3.43       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | -19.2     |\n",
      "|    reward             | 2.4244287 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 18        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 13.8      |\n",
      "|    reward             | 3.9550667 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 17.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 655      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.98    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 185      |\n",
      "|    reward             | 7.825759 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.22e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0.00149   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 225       |\n",
      "|    reward             | -5.526419 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 956       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 245       |\n",
      "|    reward             | 38.553314 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.57e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 655        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 1.27       |\n",
      "|    reward             | 0.16745205 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.0585     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 655       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 3.35      |\n",
      "|    reward             | 1.2333018 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.875     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 655         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | 30.7        |\n",
      "|    reward             | -0.43847245 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 32.8        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 13.1       |\n",
      "|    reward             | -0.4545317 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 8.74       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.98    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -187     |\n",
      "|    reward             | 4.735758 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 1.14e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.98    |\n",
      "|    explained_variance | -0.0425  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 110      |\n",
      "|    reward             | 11.09621 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 438      |\n",
      "------------------------------------\n",
      "day: 3084, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 18594185.43\n",
      "total_reward: 17594185.43\n",
      "total_cost: 16199.17\n",
      "total_trades: 10619\n",
      "Sharpe: 0.807\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 654           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 47            |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.97         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | -1.25         |\n",
      "|    reward             | -0.0072305016 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.0544        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -5.28     |\n",
      "|    reward             | 0.8710738 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 15.7      |\n",
      "|    reward             | 0.3510838 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 9.71      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -16.7      |\n",
      "|    reward             | -1.4372644 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 12.9       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 33.4      |\n",
      "|    reward             | 7.2491674 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 33.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 120      |\n",
      "|    reward             | 7.145531 |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 627      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -0.144     |\n",
      "|    reward             | -0.0393663 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.00157    |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | 4.98     |\n",
      "|    reward             | 0.710212 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 0.599    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -1.62     |\n",
      "|    reward             | 1.5221493 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.7       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.03    |\n",
      "|    explained_variance | -0.78    |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -59      |\n",
      "|    reward             | 8.209838 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 129      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -112       |\n",
      "|    reward             | -1.4289749 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 265        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 654      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 69.9     |\n",
      "|    reward             | 1.545778 |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 166      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 654       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 139       |\n",
      "|    reward             | 10.781071 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 793       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 57         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 2.45       |\n",
      "|    reward             | 0.38149896 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 654        |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.08      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | 1.48       |\n",
      "|    reward             | 0.23907658 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.0941     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 653         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -19         |\n",
      "|    reward             | -0.67727447 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 10.4        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 653          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 59           |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.1         |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 1.27         |\n",
      "|    reward             | -0.107444026 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.425        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 15.4       |\n",
      "|    reward             | -0.7362373 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 8.47       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.1     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | -41      |\n",
      "|    reward             | 7.449082 |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 52.2     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.13      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -2.84      |\n",
      "|    reward             | 0.17860651 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.315      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 653         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 62          |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.12       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 0.29        |\n",
      "|    reward             | -0.19862354 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 0.0346      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.13    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 1.37     |\n",
      "|    reward             | 1.089959 |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.3      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.14     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -9.32     |\n",
      "|    reward             | 2.706856  |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 5.08      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.13     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -5.68     |\n",
      "|    reward             | -6.205996 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 2.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.13      |\n",
      "|    explained_variance | 0.195      |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -37.3      |\n",
      "|    reward             | -1.0601572 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 50.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 1.23      |\n",
      "|    reward             | -0.253704 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 0.0653    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | -4.61      |\n",
      "|    reward             | 0.73436254 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 0.562      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.19     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 26.8      |\n",
      "|    reward             | 2.5952609 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 34.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 653        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 14.7       |\n",
      "|    reward             | -1.8404782 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 8.96       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 653       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.18     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 9.26      |\n",
      "|    reward             | 8.413777  |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 8.41      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 653      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.2     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 23.2     |\n",
      "|    reward             | 1.86038  |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 28.2     |\n",
      "------------------------------------\n",
      "day: 3084, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5521158.87\n",
      "total_reward: 4521158.87\n",
      "total_cost: 13410.27\n",
      "total_trades: 9888\n",
      "Sharpe: 0.590\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 653          |\n",
      "|    iterations         | 9300         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 46500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.21        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 9299         |\n",
      "|    policy_loss        | 1.72         |\n",
      "|    reward             | -0.052352972 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.0889       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 653         |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 71          |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.21       |\n",
      "|    explained_variance | -58.8       |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 18.5        |\n",
      "|    reward             | -0.35126558 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 15.3        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.21     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -24.6     |\n",
      "|    reward             | 0.1473746 |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 22.4      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 652         |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 73          |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.2        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | -1.45       |\n",
      "|    reward             | -0.39072788 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 1.51        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 40.9       |\n",
      "|    reward             | -0.8880109 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 129        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 652       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.17     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 137       |\n",
      "|    reward             | 1.9918308 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 893       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 652          |\n",
      "|    iterations         | 9900         |\n",
      "|    time_elapsed       | 75           |\n",
      "|    total_timesteps    | 49500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.19        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 9899         |\n",
      "|    policy_loss        | -0.0961      |\n",
      "|    reward             | -0.108152136 |\n",
      "|    std                | 1.14         |\n",
      "|    value_loss         | 0.000643     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 652        |\n",
      "|    iterations         | 10000      |\n",
      "|    time_elapsed       | 76         |\n",
      "|    total_timesteps    | 50000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9999       |\n",
      "|    policy_loss        | 13.3       |\n",
      "|    reward             | 0.34985644 |\n",
      "|    std                | 1.14       |\n",
      "|    value_loss         | 5.45       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2021-07-02T00:00:00.000000000 to  2021-10-01T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.21831734981788103\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_441_8\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 819          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 2            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.046006892 |\n",
      "-------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 753          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050377585 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.044       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    reward               | 0.25737962   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.0656       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014889853 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.00715      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.14         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000604    |\n",
      "|    reward               | -0.3941575   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.76         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 719          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062978375 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.33         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    reward               | 0.021740511  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 23.9         |\n",
      "------------------------------------------\n",
      "day: 3084, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1637179.49\n",
      "total_reward: 637179.49\n",
      "total_cost: 14569.92\n",
      "total_trades: 11806\n",
      "Sharpe: 0.341\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007602556 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.72       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.947       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.36588204  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005189161 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | -0.000348   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.6         |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    reward               | -5.7677073  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 19.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034769492 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.00223      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 55.6         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    reward               | -0.5560023   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 223          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043387767 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | -0.0364      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    reward               | -0.0607944   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 34.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009684777 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | -0.00462    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | -10.495894  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 86          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004809259 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | -0.00314    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    reward               | 1.8742733   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 699           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0038638362  |\n",
      "|    clip_fraction        | 0.0518        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.75         |\n",
      "|    explained_variance   | -0.0389       |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 39.4          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.00436      |\n",
      "|    reward               | -0.0024202324 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 64.2          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002326869 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.76       |\n",
      "|    explained_variance   | -0.00302    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | 0.6917654   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "day: 3084, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3814733.91\n",
      "total_reward: 2814733.91\n",
      "total_cost: 13626.43\n",
      "total_trades: 11141\n",
      "Sharpe: 0.501\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051262574 |\n",
      "|    clip_fraction        | 0.0416       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -0.00589     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    reward               | -0.5126036   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 240          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00542498  |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | -0.0315     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    reward               | -0.21285687 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 57.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034880654 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | -0.00127     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    reward               | -4.2224016   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060219327 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.00202      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    reward               | 0.4988174    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 221          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010704069 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000538   |\n",
      "|    reward               | -0.02867205 |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 61.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058773453 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.00324      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 273          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    reward               | -27.238913   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 366          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035151504 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | -0.00564     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    reward               | 0.07740309   |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 589          |\n",
      "------------------------------------------\n",
      "day: 3084, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 6250175.94\n",
      "total_reward: 5250175.94\n",
      "total_cost: 13345.78\n",
      "total_trades: 10555\n",
      "Sharpe: 0.585\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036522346 |\n",
      "|    clip_fraction        | 0.0492       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.81        |\n",
      "|    explained_variance   | 0.00503      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 39.3         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    reward               | -0.3873842   |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 187          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005297914 |\n",
      "|    clip_fraction        | 0.0269      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | -0.00291    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | -5.843024   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 844         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042724153 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.83        |\n",
      "|    explained_variance   | 0.00147      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 264          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    reward               | 1.1943697    |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 385          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049809846 |\n",
      "|    clip_fraction        | 0.0517       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.84        |\n",
      "|    explained_variance   | -0.00939     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    reward               | 0.11246381   |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003486319 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.83       |\n",
      "|    explained_variance   | 0.00291     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 380         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | -5.4875717  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 875         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004839087 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0.0175      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 502         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000848   |\n",
      "|    reward               | 1.1901824   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 726         |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2021-07-02T00:00:00.000000000 to  2021-10-01T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.3622668808167421\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_8\n",
      "day: 3084, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 41363682.47\n",
      "total_reward: 40363682.47\n",
      "total_cost: 19107.03\n",
      "total_trades: 8750\n",
      "Sharpe: 1.112\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 425       |\n",
      "|    time_elapsed    | 29        |\n",
      "|    total_timesteps | 12340     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -695      |\n",
      "|    critic_loss     | 6.38e+03  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 9255      |\n",
      "|    reward          | 11.853945 |\n",
      "----------------------------------\n",
      "day: 3084, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 23151899.17\n",
      "total_reward: 22151899.17\n",
      "total_cost: 999.00\n",
      "total_trades: 9252\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 386       |\n",
      "|    time_elapsed    | 63        |\n",
      "|    total_timesteps | 24680     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -269      |\n",
      "|    critic_loss     | 422       |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 21595     |\n",
      "|    reward          | 11.853945 |\n",
      "----------------------------------\n",
      "day: 3084, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 23151899.17\n",
      "total_reward: 22151899.17\n",
      "total_cost: 999.00\n",
      "total_trades: 9252\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 374       |\n",
      "|    time_elapsed    | 98        |\n",
      "|    total_timesteps | 37020     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -135      |\n",
      "|    critic_loss     | 347       |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 33935     |\n",
      "|    reward          | 11.853945 |\n",
      "----------------------------------\n",
      "day: 3084, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 23151899.17\n",
      "total_reward: 22151899.17\n",
      "total_cost: 999.00\n",
      "total_trades: 9252\n",
      "Sharpe: 0.914\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 369       |\n",
      "|    time_elapsed    | 133       |\n",
      "|    total_timesteps | 49360     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -77.9     |\n",
      "|    critic_loss     | 325       |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 46275     |\n",
      "|    reward          | 11.853945 |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2021-07-02T00:00:00.000000000 to  2021-10-01T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2021-10-01T00:00:00.000000000\n",
      "======Trading from:  2021-10-01T00:00:00.000000000 to  2021-12-31T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2021-10-01T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_504_8\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 597        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.79      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -0.412     |\n",
      "|    reward             | -0.1330457 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.0915     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 610        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.78      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -6.54      |\n",
      "|    reward             | 0.55860287 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.5        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 621       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.77     |\n",
      "|    explained_variance | -0.0247   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -3.43     |\n",
      "|    reward             | -2.225758 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.92      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 628      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.78    |\n",
      "|    explained_variance | 0.00333  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -34.6    |\n",
      "|    reward             | 5.017647 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 58.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 632       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.78     |\n",
      "|    explained_variance | -0.014    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -16.4     |\n",
      "|    reward             | 6.5609674 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 93.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.77     |\n",
      "|    explained_variance | -9.45e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -350      |\n",
      "|    reward             | -87.71026 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.42e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 629         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.8        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 1.09        |\n",
      "|    reward             | -0.12385675 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.0756      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 630       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 3.32      |\n",
      "|    reward             | 0.5185118 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.629     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 632         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 0.649       |\n",
      "|    reward             | -0.18911824 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.0729      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 633        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.84      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -2.95      |\n",
      "|    reward             | 0.09283635 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.805      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 634       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83     |\n",
      "|    explained_variance | 0.002     |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 12.5      |\n",
      "|    reward             | 0.8857808 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 19.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 636       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.84     |\n",
      "|    explained_variance | -0.00699  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -110      |\n",
      "|    reward             | 12.628536 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 338       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 637         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.44       |\n",
      "|    reward             | -0.06823755 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.00656     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 638          |\n",
      "|    iterations         | 1400         |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 7000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.87        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 1399         |\n",
      "|    policy_loss        | 1.03         |\n",
      "|    reward             | -0.124812484 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.062        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 639        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -0.172     |\n",
      "|    reward             | -0.8835553 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.0561     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 640        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.91      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 1.91       |\n",
      "|    reward             | -2.6353662 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.453      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 640       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -9.7      |\n",
      "|    reward             | 15.588411 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 35.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 641       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.93     |\n",
      "|    explained_variance | 0.0015    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 141       |\n",
      "|    reward             | -6.022789 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 575       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 641         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -0.429      |\n",
      "|    reward             | -0.04756918 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.00838     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 642        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -3.46      |\n",
      "|    reward             | -0.2692323 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.515      |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 642         |\n",
      "|    iterations         | 2100        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 10500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2099        |\n",
      "|    policy_loss        | -5.5        |\n",
      "|    reward             | 0.012671707 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 1.43        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 642        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 4.31       |\n",
      "|    reward             | -1.1603789 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.26       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 641        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | 33.1       |\n",
      "|    reward             | 0.08642383 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 36.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 641       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -0.00747  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -4.44     |\n",
      "|    reward             | -4.952519 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 14.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 642       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 115       |\n",
      "|    reward             | 14.341722 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 400       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 642         |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | 0.842       |\n",
      "|    reward             | -0.48435754 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.0451      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 642       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 2.72      |\n",
      "|    reward             | -1.12729  |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.984     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 642       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 11.5      |\n",
      "|    reward             | 1.0153924 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 5.24      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 643         |\n",
      "|    iterations         | 2900        |\n",
      "|    time_elapsed       | 22          |\n",
      "|    total_timesteps    | 14500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.97       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2899        |\n",
      "|    policy_loss        | -1.12       |\n",
      "|    reward             | -0.46689737 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.116       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 643        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 31.3       |\n",
      "|    reward             | -1.1065825 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 20.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 643        |\n",
      "|    iterations         | 3100       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 15500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | -0.153     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3099       |\n",
      "|    policy_loss        | 6.65       |\n",
      "|    reward             | -2.7598119 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 4.87       |\n",
      "--------------------------------------\n",
      "day: 3147, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2543251.34\n",
      "total_reward: 1543251.34\n",
      "total_cost: 6992.82\n",
      "total_trades: 7751\n",
      "Sharpe: 0.451\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 643        |\n",
      "|    iterations         | 3200       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 16000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3199       |\n",
      "|    policy_loss        | -0.367     |\n",
      "|    reward             | 0.14085826 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.00553    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 643        |\n",
      "|    iterations         | 3300       |\n",
      "|    time_elapsed       | 25         |\n",
      "|    total_timesteps    | 16500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3299       |\n",
      "|    policy_loss        | -0.345     |\n",
      "|    reward             | 0.09655751 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.0278     |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 644         |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 26          |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.00537    |\n",
      "|    reward             | 0.070552155 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 1.49        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 27         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | 4.1        |\n",
      "|    reward             | 0.21176757 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.781      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 4.08      |\n",
      "|    reward             | -6.687325 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.04      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -121      |\n",
      "|    reward             | 5.0950127 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 525       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 644         |\n",
      "|    iterations         | 3800        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 19000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3799        |\n",
      "|    policy_loss        | -1.4        |\n",
      "|    reward             | 0.022683725 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.051       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 645          |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.07        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 0.103        |\n",
      "|    reward             | -0.011932484 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.000518     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 645           |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.16         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0005        |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | -0.0383       |\n",
      "|    reward             | -0.0012918967 |\n",
      "|    std                | 1.13          |\n",
      "|    value_loss         | 8.48e-05      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 31         |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.23      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | -0.666     |\n",
      "|    reward             | 0.40403676 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 0.0111     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 32         |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.24      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 2.49       |\n",
      "|    reward             | -2.1393507 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 33.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.24     |\n",
      "|    explained_variance | -0.0015   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -11.7     |\n",
      "|    reward             | 12.504082 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 23        |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 34         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.24      |\n",
      "|    explained_variance | -0.00267   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 175        |\n",
      "|    reward             | -10.380859 |\n",
      "|    std                | 1.15       |\n",
      "|    value_loss         | 748        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.27     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 4.1       |\n",
      "|    reward             | 0.6948791 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 1.02      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 645          |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 35           |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.27        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | 0.267        |\n",
      "|    reward             | -0.023579447 |\n",
      "|    std                | 1.16         |\n",
      "|    value_loss         | 0.0139       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 646         |\n",
      "|    iterations         | 4700        |\n",
      "|    time_elapsed       | 36          |\n",
      "|    total_timesteps    | 23500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4699        |\n",
      "|    policy_loss        | 2.04        |\n",
      "|    reward             | -0.16764025 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.18        |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 646       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.27     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 0.0759    |\n",
      "|    reward             | 5.5765996 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 26.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 646        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.28      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | 102        |\n",
      "|    reward             | -0.8459521 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 382        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 646       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.27     |\n",
      "|    explained_variance | -0.00254  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 8.89      |\n",
      "|    reward             | -7.525511 |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 90.8      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 646         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | -2.81       |\n",
      "|    reward             | -0.07475685 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.201       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 646        |\n",
      "|    iterations         | 5200       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 26000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5199       |\n",
      "|    policy_loss        | 8.27       |\n",
      "|    reward             | 0.22776052 |\n",
      "|    std                | 1.16       |\n",
      "|    value_loss         | 2.03       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 646         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 40          |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.29       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | 2.02        |\n",
      "|    reward             | -0.77781856 |\n",
      "|    std                | 1.17        |\n",
      "|    value_loss         | 0.215       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 646       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.3      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -8.78     |\n",
      "|    reward             | -3.035024 |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 4.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 646       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.32     |\n",
      "|    explained_variance | 0.000843  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 156       |\n",
      "|    reward             | 0.2688656 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.28e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 646       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.32     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 151       |\n",
      "|    reward             | 29.574564 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.1e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -1.4      |\n",
      "|    reward             | 0.0815232 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.0459    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 646        |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 44         |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 0.48       |\n",
      "|    reward             | 0.57377887 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 645         |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 45          |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | 7.25        |\n",
      "|    reward             | -0.47420385 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 2.18        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6000       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 30000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5999       |\n",
      "|    policy_loss        | 61.2       |\n",
      "|    reward             | -1.9235156 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 112        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 163       |\n",
      "|    reward             | -9.954162 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.12e+03  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 99.6       |\n",
      "|    reward             | -21.879496 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 511        |\n",
      "--------------------------------------\n",
      "day: 3147, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 21316948.99\n",
      "total_reward: 20316948.99\n",
      "total_cost: 19100.68\n",
      "total_trades: 9921\n",
      "Sharpe: 0.988\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6300       |\n",
      "|    time_elapsed       | 48         |\n",
      "|    total_timesteps    | 31500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.31      |\n",
      "|    explained_variance | -835       |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6299       |\n",
      "|    policy_loss        | 14         |\n",
      "|    reward             | 0.02155777 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 6.1        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.34      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 7.02       |\n",
      "|    reward             | 0.38963857 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 1.41       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.36      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 0.622      |\n",
      "|    reward             | 0.04377029 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.231      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6600       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 33000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.34      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6599       |\n",
      "|    policy_loss        | 20.8       |\n",
      "|    reward             | -0.4402559 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 10.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.33     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -3.59     |\n",
      "|    reward             | -8.976156 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 7.55      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 17.3       |\n",
      "|    reward             | 12.5102005 |\n",
      "|    std                | 1.17       |\n",
      "|    value_loss         | 229        |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 6900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 34500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.31    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 6899     |\n",
      "|    policy_loss        | -163     |\n",
      "|    reward             | 92.00009 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 1.74e+03 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.34      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 0.819      |\n",
      "|    reward             | 0.07817613 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.0434     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | -3.85      |\n",
      "|    reward             | 0.26667675 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 0.664      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.35      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 5.07       |\n",
      "|    reward             | -0.7987007 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 1.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 56         |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.35      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | -3.2128549 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 7.6        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.34     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 673       |\n",
      "|    reward             | 5.2791395 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 1.52e+04  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 58         |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.33      |\n",
      "|    explained_variance | 0.00484    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | -62.4      |\n",
      "|    reward             | -25.582937 |\n",
      "|    std                | 1.18       |\n",
      "|    value_loss         | 532        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 644         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 58          |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.35       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 2.59        |\n",
      "|    reward             | 0.011939117 |\n",
      "|    std                | 1.18        |\n",
      "|    value_loss         | 0.183       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.34     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 4.27      |\n",
      "|    reward             | 0.1315872 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.779     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.35     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -4.09     |\n",
      "|    reward             | 2.2996063 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.34     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 11.7      |\n",
      "|    reward             | -3.795545 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 6.36      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 644      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.34    |\n",
      "|    explained_variance | -0.0149  |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 139      |\n",
      "|    reward             | 2.488362 |\n",
      "|    std                | 1.18     |\n",
      "|    value_loss         | 702      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.34     |\n",
      "|    explained_variance | 0.0475    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -121      |\n",
      "|    reward             | 20.211514 |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 487       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 644          |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 63           |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.36        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | 0.651        |\n",
      "|    reward             | -0.027895061 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 0.00943      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 64         |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.37      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | -1         |\n",
      "|    reward             | -0.6293616 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 0.0814     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.37     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -1.29     |\n",
      "|    reward             | 0.7685258 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 0.0621    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 65         |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.37      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -27.4      |\n",
      "|    reward             | -1.1581898 |\n",
      "|    std                | 1.19       |\n",
      "|    value_loss         | 22.8       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 66         |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.39      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 70         |\n",
      "|    reward             | -18.605099 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 316        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.39     |\n",
      "|    explained_variance | -0.000412 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 215       |\n",
      "|    reward             | 24.12412  |\n",
      "|    std                | 1.2       |\n",
      "|    value_loss         | 1.35e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.41      |\n",
      "|    explained_variance | -0.000252  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 414        |\n",
      "|    reward             | -7.1468697 |\n",
      "|    std                | 1.2        |\n",
      "|    value_loss         | 7.57e+03   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 644          |\n",
      "|    iterations         | 8900         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 44500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.42        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 8899         |\n",
      "|    policy_loss        | 4.2          |\n",
      "|    reward             | 0.0067296997 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.577        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 644         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 69          |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.43       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | 0.545       |\n",
      "|    reward             | 0.026740432 |\n",
      "|    std                | 1.21        |\n",
      "|    value_loss         | 0.132       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 9100       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 45500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.43      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9099       |\n",
      "|    policy_loss        | 9.85       |\n",
      "|    reward             | 0.06041729 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.93       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 644       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.44     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 106       |\n",
      "|    reward             | 1.9031022 |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 818       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 644        |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.44      |\n",
      "|    explained_variance | 0.00337    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -246       |\n",
      "|    reward             | -3.9135706 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.28e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.43      |\n",
      "|    explained_variance | 0.0395     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | -48.9      |\n",
      "|    reward             | 0.24232145 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 1.97e+03   |\n",
      "--------------------------------------\n",
      "day: 3147, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 17491972.38\n",
      "total_reward: 16491972.38\n",
      "total_cost: 18644.06\n",
      "total_trades: 11074\n",
      "Sharpe: 0.936\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 9500       |\n",
      "|    time_elapsed       | 73         |\n",
      "|    total_timesteps    | 47500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.44      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9499       |\n",
      "|    policy_loss        | -7.73      |\n",
      "|    reward             | 0.26371795 |\n",
      "|    std                | 1.21       |\n",
      "|    value_loss         | 2.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.45      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 0.108      |\n",
      "|    reward             | -0.8220013 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 0.142      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 645        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.45      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | -1.9754261 |\n",
      "|    std                | 1.22       |\n",
      "|    value_loss         | 3.28       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.45     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -6.37     |\n",
      "|    reward             | 2.5538416 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 2.62      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.46     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 89.4      |\n",
      "|    reward             | -6.350054 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 585       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 645       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.46     |\n",
      "|    explained_variance | -0.000561 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 182       |\n",
      "|    reward             | 5.8692613 |\n",
      "|    std                | 1.22      |\n",
      "|    value_loss         | 1.84e+03  |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2021-10-01T00:00:00.000000000 to  2021-12-31T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  0.1751852519191187\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_504_8\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 828        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 2          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.30341336 |\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 758         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006704339 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | -0.00706    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.268       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | 0.20810717  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.722       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058867093 |\n",
      "|    clip_fraction        | 0.0399       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 18.7         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    reward               | -3.095095    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 719         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006013407 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 4.62        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    reward               | -0.3297285  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005948444 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.25        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    reward               | 0.022426616 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004281749 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.21        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.000819   |\n",
      "|    reward               | 0.57819587  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "day: 3147, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1336339.60\n",
      "total_reward: 336339.60\n",
      "total_cost: 16287.85\n",
      "total_trades: 12291\n",
      "Sharpe: 0.370\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053242156 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.08         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    reward               | 1.1301395    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054863496 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.5          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.017161414 |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004895335 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.77       |\n",
      "|    explained_variance   | 0.000171    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | 4.4648166   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043091625 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.00902      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 62.7         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -0.66191703  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012424851 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -0.00299     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    reward               | 0.004349481  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 398          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053137643 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 294          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    reward               | -0.21845542  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 354          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006024489 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    reward               | 3.8399742   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "day: 3147, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4476268.54\n",
      "total_reward: 3476268.54\n",
      "total_cost: 15103.13\n",
      "total_trades: 12395\n",
      "Sharpe: 0.513\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 692           |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 41            |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.003261258   |\n",
      "|    clip_fraction        | 0.0203        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.74         |\n",
      "|    explained_variance   | 0.0122        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 124           |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.00883      |\n",
      "|    reward               | -0.0027994274 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 346           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044517913 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | -0.001       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 324          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 3.8111548    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 760          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004656614 |\n",
      "|    clip_fraction        | 0.0458      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | -0.0463     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000186   |\n",
      "|    reward               | -0.88084334 |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 24          |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 690           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 50            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.003370562   |\n",
      "|    clip_fraction        | 0.0134        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.75         |\n",
      "|    explained_variance   | 0.0263        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 150           |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.0042       |\n",
      "|    reward               | -0.0030785408 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 222           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028542317 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -0.00265     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 223          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    reward               | -1.0369251   |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 662          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025374258 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | -0.00409     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.81         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000841    |\n",
      "|    reward               | 0.094400145  |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 31.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 689           |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 59            |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.005065834   |\n",
      "|    clip_fraction        | 0.0221        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.77         |\n",
      "|    explained_variance   | 0.0294        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 451           |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.00438      |\n",
      "|    reward               | -0.0029819102 |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 579           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 688          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060560135 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.77        |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    reward               | 1.7328393    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 424          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 3147, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2365348.57\n",
      "total_reward: 1365348.57\n",
      "total_cost: 16105.32\n",
      "total_trades: 11947\n",
      "Sharpe: 0.434\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 688          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061406945 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.78         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    reward               | 0.037003245  |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008859159 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    reward               | -0.9045993  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 83.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006421945 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.82       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.3         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | -1.4142945  |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 8.39        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055909804 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.85        |\n",
      "|    explained_variance   | -0.0231      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.34         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000792    |\n",
      "|    reward               | 0.20876946   |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 4.01         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2021-10-01T00:00:00.000000000 to  2021-12-31T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  -0.16348502632268883\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_8\n",
      "day: 3147, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 427       |\n",
      "|    time_elapsed    | 29        |\n",
      "|    total_timesteps | 12592     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.78e+04 |\n",
      "|    critic_loss     | 1.52e+05  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 9444      |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 3147, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 391       |\n",
      "|    time_elapsed    | 64        |\n",
      "|    total_timesteps | 25184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.22e+04 |\n",
      "|    critic_loss     | 6.21e+04  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 22036     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "day: 3147, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1000000.00\n",
      "total_reward: 0.00\n",
      "total_cost: 0.00\n",
      "total_trades: 0\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 380       |\n",
      "|    time_elapsed    | 99        |\n",
      "|    total_timesteps | 37776     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.31e+03 |\n",
      "|    critic_loss     | 1.63e+04  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 34628     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 375       |\n",
      "|    time_elapsed    | 134       |\n",
      "|    total_timesteps | 50368     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.26e+03 |\n",
      "|    critic_loss     | 3.85e+03  |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 47220     |\n",
      "|    reward          | 0.0       |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2021-10-01T00:00:00.000000000 to  2021-12-31T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2021-12-31T00:00:00.000000000\n",
      "======Trading from:  2021-12-31T00:00:00.000000000 to  2022-04-01T00:00:00.000000000\n",
      "============================================\n",
      "turbulence_threshold:  37.923537735586116\n",
      "======Model training from:  2009-04-01 to  2021-12-31T00:00:00.000000000\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0005}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_567_5\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 647          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.84        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -1.71        |\n",
      "|    reward             | -0.017306896 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 0.205        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 647        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -0.26      |\n",
      "|    reward             | 0.39465508 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.0862     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 648        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -7.78      |\n",
      "|    reward             | -0.6535673 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 2.9        |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 649       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -29.5     |\n",
      "|    reward             | 4.1971974 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 35.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 649       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | -0.00312  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -0.758    |\n",
      "|    reward             | 3.4905672 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 650        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.85      |\n",
      "|    explained_variance | 0.047      |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -89.1      |\n",
      "|    reward             | -53.099064 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 1.03e+03   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 650          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.86        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | -2.63        |\n",
      "|    reward             | -0.038351696 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.347        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 650         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -4.03       |\n",
      "|    reward             | -0.76207566 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 0.594       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.86     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -7.98     |\n",
      "|    reward             | 1.1677397 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.87     |\n",
      "|    explained_variance | 0.00657   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -35.5     |\n",
      "|    reward             | 1.0470192 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 31.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88     |\n",
      "|    explained_variance | 0.00378   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 26.7      |\n",
      "|    reward             | 15.563662 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 105       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | -0.0325    |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -45.5      |\n",
      "|    reward             | -13.569842 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 461        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 650        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 1.01       |\n",
      "|    reward             | 0.45101044 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0286     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -7.88       |\n",
      "|    reward             | -0.51309884 |\n",
      "|    std                | 1.05        |\n",
      "|    value_loss         | 2.08        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85     |\n",
      "|    explained_variance | 0.0999    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 4.27      |\n",
      "|    reward             | 0.8272866 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.778     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | -0.041    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -23       |\n",
      "|    reward             | 0.4882452 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 23.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -45.4      |\n",
      "|    reward             | -10.404065 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 63.9       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.89    |\n",
      "|    explained_variance | 0.0127   |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 30.8     |\n",
      "|    reward             | 11.92487 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 124      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.9      |\n",
      "|    explained_variance | 0.00295   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 33.6      |\n",
      "|    reward             | 13.618564 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 392       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 14.1       |\n",
      "|    reward             | 0.15574914 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 6.07       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -6.28      |\n",
      "|    reward             | -1.1015216 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 1.32       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 651          |\n",
      "|    iterations         | 2200         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 11000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.95        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0005       |\n",
      "|    n_updates          | 2199         |\n",
      "|    policy_loss        | 7.11         |\n",
      "|    reward             | -0.080281764 |\n",
      "|    std                | 1.07         |\n",
      "|    value_loss         | 14.4         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 11500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 7.98     |\n",
      "|    reward             | -5.13233 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 5.99     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.92     |\n",
      "|    explained_variance | -0.00367  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -195      |\n",
      "|    reward             | 20.586464 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 992       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 123       |\n",
      "|    reward             | 1.0728844 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.22e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -0.107     |\n",
      "|    reward             | 0.16737443 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 0.0372     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.96       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 5.09        |\n",
      "|    reward             | -0.43916595 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.97      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -9.42      |\n",
      "|    reward             | 0.14734979 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 5.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -0.247    |\n",
      "|    reward             | 2.5576887 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 7.48      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 23         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 71.3       |\n",
      "|    reward             | -2.0138288 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 292        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -0.000899 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 119       |\n",
      "|    reward             | -16.44745 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 510       |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.94    |\n",
      "|    explained_variance | -0.00126 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 78.8     |\n",
      "|    reward             | 35.80926 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 2.26e+03 |\n",
      "------------------------------------\n",
      "day: 3210, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 36604451.39\n",
      "total_reward: 35604451.39\n",
      "total_cost: 18512.98\n",
      "total_trades: 11974\n",
      "Sharpe: 0.992\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -2.05     |\n",
      "|    reward             | 1.5684084 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.247     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.96     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -1.67     |\n",
      "|    reward             | 2.8835466 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | 0.00145   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 24.7      |\n",
      "|    reward             | 5.5671315 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 76.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95     |\n",
      "|    explained_variance | -3.15e-05 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | -34.2     |\n",
      "|    reward             | 9.009     |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 90.7      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 28         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.96      |\n",
      "|    explained_variance | -0.000418  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | -346       |\n",
      "|    reward             | -15.273434 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 6.07e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 364       |\n",
      "|    reward             | 21.926254 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 6.25e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 29          |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 2.36        |\n",
      "|    reward             | -0.12238796 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.224       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -10.9      |\n",
      "|    reward             | -0.6482293 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 5.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 26.7      |\n",
      "|    reward             | 2.6518288 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 17.8      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 1.52     |\n",
      "|    reward             | 4.077991 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 8.86     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6        |\n",
      "|    explained_variance | -0.00181  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -112      |\n",
      "|    reward             | 30.710321 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.09e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 33         |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.01      |\n",
      "|    explained_variance | -0.014     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 322        |\n",
      "|    reward             | -12.748424 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 2.85e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -0.0967     |\n",
      "|    reward             | -0.07611395 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 0.000658    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 5.1       |\n",
      "|    reward             | 1.2069042 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.01     |\n",
      "|    explained_variance | 0.0299    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -72.2     |\n",
      "|    reward             | 7.2291684 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 199       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 41.1      |\n",
      "|    reward             | -9.980877 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 78.5      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.03      |\n",
      "|    explained_variance | -2.86e-05  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -66.8      |\n",
      "|    reward             | 0.13431144 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 167        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.03     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 526       |\n",
      "|    reward             | 50.279755 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 8.14e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -885     |\n",
      "|    reward             | 38.88439 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.3e+04  |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 39          |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.06       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -1.98       |\n",
      "|    reward             | -0.36773694 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 0.454       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 40         |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | 0.139      |\n",
      "|    reward             | -1.0454994 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 0.795      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -5.22      |\n",
      "|    reward             | 0.41258928 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 10.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 39.9      |\n",
      "|    reward             | 0.872358  |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 60.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 42         |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 494        |\n",
      "|    reward             | -27.721872 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 6.79e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.09    |\n",
      "|    explained_variance | -0.00805 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -95.3    |\n",
      "|    reward             | 40.83931 |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 529      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 5800        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 29000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.1        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 5799        |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | 0.017753366 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0938      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 45         |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -2.92      |\n",
      "|    reward             | -3.7420232 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 4.43       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -9.17     |\n",
      "|    reward             | -6.570679 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 15.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | -0.00664  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -57.4     |\n",
      "|    reward             | -2.332683 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 101       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | 34.3       |\n",
      "|    reward             | -0.6270178 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 205        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.11     |\n",
      "|    explained_variance | 0.00946   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -14.5     |\n",
      "|    reward             | -4.200537 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 225       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 178       |\n",
      "|    reward             | -20.62477 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.8e+03   |\n",
      "-------------------------------------\n",
      "day: 3210, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 20118927.03\n",
      "total_reward: 19118927.03\n",
      "total_cost: 15298.76\n",
      "total_trades: 8063\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | 11.8       |\n",
      "|    reward             | 0.19304086 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 5.2        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 6.74      |\n",
      "|    reward             | 2.731805  |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -38.9     |\n",
      "|    reward             | 13.347232 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 58.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -93.9     |\n",
      "|    reward             | 2.594919  |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 232       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 6900       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 34500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | 2.91e-05   |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6899       |\n",
      "|    policy_loss        | -47.1      |\n",
      "|    reward             | -25.164253 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 406        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 53         |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | -0.000118  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -40.1      |\n",
      "|    reward             | -18.781263 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 980        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 7100       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 35500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7099       |\n",
      "|    policy_loss        | 1.34       |\n",
      "|    reward             | 0.27360263 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 0.171      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 29.5       |\n",
      "|    reward             | -1.7228243 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 28         |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 26.4      |\n",
      "|    reward             | 2.7742927 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 38.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.09     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 4.65      |\n",
      "|    reward             | 2.6872528 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 2.85      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 7500     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 37500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7499     |\n",
      "|    policy_loss        | -16.2    |\n",
      "|    reward             | 6.56222  |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 222      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.08     |\n",
      "|    explained_variance | -0.00335  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -119      |\n",
      "|    reward             | 10.254086 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 433       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 59         |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.08      |\n",
      "|    explained_variance | -3.49e-05  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | 2.01e+03   |\n",
      "|    reward             | -56.755337 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 2.1e+05    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 8.7       |\n",
      "|    reward             | 0.7317851 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.49      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 60         |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -16.4      |\n",
      "|    reward             | 0.91873217 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 8.72       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 12.4     |\n",
      "|    reward             | -8.05971 |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 15.6     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | 0.0093     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -9.01      |\n",
      "|    reward             | -1.1134443 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 25.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 0.0647    |\n",
      "|    reward             | -45.0529  |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 154       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 63         |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.09      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | 229        |\n",
      "|    reward             | -34.505196 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 4.43e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | -0.059      |\n",
      "|    reward             | -0.16229935 |\n",
      "|    std                | 1.11        |\n",
      "|    value_loss         | 0.0276      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 18.3      |\n",
      "|    reward             | -2.836566 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 9.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.1     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -7.5     |\n",
      "|    reward             | 9.156161 |\n",
      "|    std                | 1.11     |\n",
      "|    value_loss         | 20.8     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 6.77      |\n",
      "|    reward             | 0.5077308 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 4.99      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.1      |\n",
      "|    explained_variance | -0.0133   |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 131       |\n",
      "|    reward             | 29.269577 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 838       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 68         |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.11      |\n",
      "|    explained_variance | 0.0134     |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -817       |\n",
      "|    reward             | -208.22852 |\n",
      "|    std                | 1.11       |\n",
      "|    value_loss         | 1.78e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 69         |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | 0.969      |\n",
      "|    reward             | 0.11615214 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.0333     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.14     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -6.92     |\n",
      "|    reward             | -2.074336 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 1.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 70         |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.14      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 8.83       |\n",
      "|    reward             | -1.3759251 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 4.75       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 651      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.14    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0005   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 3.59     |\n",
      "|    reward             | 7.903395 |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 0.944    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 9400       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 47000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9399       |\n",
      "|    policy_loss        | 348        |\n",
      "|    reward             | -40.483814 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 4.18e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.12     |\n",
      "|    explained_variance | 0.0313    |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -127      |\n",
      "|    reward             | 24.796349 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 906       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -418      |\n",
      "|    reward             | 39.326134 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 5.14e+03  |\n",
      "-------------------------------------\n",
      "day: 3210, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 53513665.26\n",
      "total_reward: 52513665.26\n",
      "total_cost: 18933.78\n",
      "total_trades: 10995\n",
      "Sharpe: 1.045\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 651       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0005    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 2.87      |\n",
      "|    reward             | 0.3789811 |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.56      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -4.47      |\n",
      "|    reward             | -1.5163041 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 0.722      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 651        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 75         |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0005     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 32.5       |\n",
      "|    reward             | -1.2599508 |\n",
      "|    std                | 1.12       |\n",
      "|    value_loss         | 48.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 651         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.11       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0005      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 74.1        |\n",
      "|    reward             | -0.50979483 |\n",
      "|    std                | 1.12        |\n",
      "|    value_loss         | 118         |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======A2C Validation from:  2021-12-31T00:00:00.000000000 to  2022-04-01T00:00:00.000000000\n",
      "A2C Sharpe Ratio:  -0.04997450835411111\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_567_5\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 831         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 2           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.25519603 |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 750           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 5             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0024073985  |\n",
      "|    clip_fraction        | 0.0279        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0991        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00075      |\n",
      "|    reward               | -0.0121004395 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 0.333         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029274584 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.424        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    reward               | 0.7430404    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.24         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005187692 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.312       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    reward               | 0.044284165 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.732       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048053996 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.55         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    reward               | 0.044897523  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004557414 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.66        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    reward               | 0.02021403  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 6.14        |\n",
      "-----------------------------------------\n",
      "day: 3210, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4715703.34\n",
      "total_reward: 3715703.34\n",
      "total_cost: 17595.81\n",
      "total_trades: 12468\n",
      "Sharpe: 0.817\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008722123 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | -0.00373    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.45        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.13861138 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.38        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054615177 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | -0.00345     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 21.9         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | 0.054608412  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 96.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061014676 |\n",
      "|    clip_fraction        | 0.0325       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000977    |\n",
      "|    reward               | 1.2974895    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 227          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058589564 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.99         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    reward               | 0.17760268   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.98         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 693           |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 32            |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0042572953  |\n",
      "|    clip_fraction        | 0.0171        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.149         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 46.1          |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.00566      |\n",
      "|    reward               | -0.0012421912 |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 272           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010123079 |\n",
      "|    clip_fraction        | 0.00479      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.061373614  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 329          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007914664 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.3         |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    reward               | 0.017996538 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019603458 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 470          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    reward               | 29.811739    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 596          |\n",
      "------------------------------------------\n",
      "day: 3210, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 10313981.53\n",
      "total_reward: 9313981.53\n",
      "total_cost: 16321.24\n",
      "total_trades: 12244\n",
      "Sharpe: 0.872\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062114573 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 77.4         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    reward               | -2.5567203   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002975997 |\n",
      "|    clip_fraction        | 0.00986     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    reward               | 0.05518968  |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 508         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 690        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00603153 |\n",
      "|    clip_fraction        | 0.0237     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.67      |\n",
      "|    explained_variance   | 0.296      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 198        |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00503   |\n",
      "|    reward               | 3.4658415  |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 641        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065398533 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.67        |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 59.6         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | -0.11223405  |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 88.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003812821 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | -0.1353659  |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 841         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003716447 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 638         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    reward               | 6.1681466   |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005820766 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -1.6514119  |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "day: 3210, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 13571438.16\n",
      "total_reward: 12571438.16\n",
      "total_cost: 15498.83\n",
      "total_trades: 11895\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008358834 |\n",
      "|    clip_fraction        | 0.0544      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 463         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | 0.061719548 |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826743 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 634         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    reward               | 3.8255618   |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011855837 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.67       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 0.25641116  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 688          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058374032 |\n",
      "|    clip_fraction        | 0.0505       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 220          |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | -30.486507   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2021-12-31T00:00:00.000000000 to  2022-04-01T00:00:00.000000000\n",
      "PPO Sharpe Ratio:  0.03205636483171652\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_5\n",
      "day: 3210, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8773087.66\n",
      "total_reward: 7773087.66\n",
      "total_cost: 999.00\n",
      "total_trades: 6420\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 426      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 12844    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.62e+03 |\n",
      "|    critic_loss     | 5.1e+03  |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 9633     |\n",
      "|    reward          | 57.17938 |\n",
      "---------------------------------\n",
      "day: 3210, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8773087.66\n",
      "total_reward: 7773087.66\n",
      "total_cost: 999.00\n",
      "total_trades: 6420\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 386      |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 25688    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 737      |\n",
      "|    critic_loss     | 439      |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 22477    |\n",
      "|    reward          | 57.17938 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 373      |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 38532    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 324      |\n",
      "|    critic_loss     | 384      |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 35321    |\n",
      "|    reward          | 57.17938 |\n",
      "---------------------------------\n",
      "day: 3210, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 8773087.66\n",
      "total_reward: 7773087.66\n",
      "total_cost: 999.00\n",
      "total_trades: 6420\n",
      "Sharpe: 0.598\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 365      |\n",
      "|    time_elapsed    | 140      |\n",
      "|    total_timesteps | 51376    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 136      |\n",
      "|    critic_loss     | 392      |\n",
      "|    learning_rate   | 0.0005   |\n",
      "|    n_updates       | 48165    |\n",
      "|    reward          | 57.17938 |\n",
      "---------------------------------\n",
      "======DDPG Validation from:  2021-12-31T00:00:00.000000000 to  2022-04-01T00:00:00.000000000\n",
      "======Best Model Retraining from:  2009-04-01 to  2022-04-01T00:00:00.000000000\n",
      "======Trading from:  2022-04-01T00:00:00.000000000 to  2022-07-05T00:00:00.000000000\n",
      "Ensemble Strategy took:  39.488526244958244  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "-0qd8acMtj1f",
    "outputId": "a7cc6220-7c14-4b18-964d-c79c1aca731d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.158899</td>\n",
       "      <td>0.318541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.116941</td>\n",
       "      <td>0.152668</td>\n",
       "      <td>-0.267598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.128159</td>\n",
       "      <td>0.119817</td>\n",
       "      <td>0.102233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.038973</td>\n",
       "      <td>0.021581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2021-04-05</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>PPO</td>\n",
       "      <td>0.399388</td>\n",
       "      <td>0.515511</td>\n",
       "      <td>0.098758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2021-07-02</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.218317</td>\n",
       "      <td>-0.362267</td>\n",
       "      <td>-0.141015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.175185</td>\n",
       "      <td>-0.163485</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>PPO</td>\n",
       "      <td>-0.049975</td>\n",
       "      <td>0.032056</td>\n",
       "      <td>-0.242383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Iter  Val Start    Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0  126 2020-04-02 2020-07-02        PPO   0.158899   0.318541         0.0\n",
       "1  189 2020-07-02 2020-10-01        PPO   0.116941   0.152668   -0.267598\n",
       "2  252 2020-10-01 2020-12-31        A2C   0.128159   0.119817    0.102233\n",
       "3  315 2020-12-31 2021-04-05        A2C   0.038973   0.021581         0.0\n",
       "4  378 2021-04-05 2021-07-02        PPO   0.399388   0.515511    0.098758\n",
       "5  441 2021-07-02 2021-10-01       DDPG  -0.218317  -0.362267   -0.141015\n",
       "6  504 2021-10-01 2021-12-31        A2C   0.175185  -0.163485         0.0\n",
       "7  567 2021-12-31 2022-04-01        PPO  -0.049975   0.032056   -0.242383"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed[(processed.date > val_test_start)&(processed.date <= val_test_end)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9mKF7GGtj1g",
    "outputId": "747f2942-010b-4df8-c66f-5cc2a583e704",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  -0.15668713878488635\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oyosyW7_tj1g",
    "outputId": "212cbdca-a5e4-46b7-f55d-ec97aef18bc4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000005e+06</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2020-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000023e+06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2020-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.001093e+06</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>2020-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001209e+06</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>2020-07-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return   datadate\n",
       "0   1.000000e+06  2020-07-02           NaN 2020-07-02\n",
       "1   1.000005e+06  2020-07-06      0.000005 2020-07-06\n",
       "2   1.000023e+06  2020-07-07      0.000018 2020-07-07\n",
       "3   1.001093e+06  2020-07-08      0.001071 2020-07-08\n",
       "4   1.001209e+06  2020-07-09      0.000115 2020-07-09"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "wLsRdw2Ctj1h",
    "outputId": "ac0405c7-0f0b-4309-9878-b6e115431926"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "8bc18db6-17cc-4763-f3a5-01083861401d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return         -0.070267\n",
      "Cumulative returns    -0.135596\n",
      "Annual volatility      0.256730\n",
      "Sharpe ratio          -0.156687\n",
      "Calmar ratio          -0.175760\n",
      "Stability              0.063913\n",
      "Max drawdown          -0.399789\n",
      "Omega ratio            0.965215\n",
      "Sortino ratio         -0.226552\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.855817\n",
      "Daily value at risk   -0.032505\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiHhM1YkoCel",
    "outputId": "63d7e627-d1d2-42b5-9038-17aa4ce853cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (504, 8)\n",
      "Annual return          0.093554\n",
      "Cumulative returns     0.195860\n",
      "Annual volatility      0.157482\n",
      "Sharpe ratio           0.647896\n",
      "Calmar ratio           0.498165\n",
      "Stability              0.541829\n",
      "Max drawdown          -0.187797\n",
      "Omega ratio            1.114785\n",
      "Sortino ratio          0.901417\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.910244\n",
      "Daily value at risk   -0.019436\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000005e+06</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2020-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000023e+06</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2020-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.001093e+06</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>2020-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001209e+06</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>2020-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>9.242817e+05</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>-0.007164</td>\n",
       "      <td>2022-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>9.013652e+05</td>\n",
       "      <td>2022-06-28</td>\n",
       "      <td>-0.024794</td>\n",
       "      <td>2022-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>8.900220e+05</td>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>-0.012584</td>\n",
       "      <td>2022-06-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>8.799103e+05</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>-0.011361</td>\n",
       "      <td>2022-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>8.644041e+05</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>-0.017623</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account_value        date  daily_return   datadate\n",
       "0     1.000000e+06  2020-07-02           NaN 2020-07-02\n",
       "1     1.000005e+06  2020-07-06      0.000005 2020-07-06\n",
       "2     1.000023e+06  2020-07-07      0.000018 2020-07-07\n",
       "3     1.001093e+06  2020-07-08      0.001071 2020-07-08\n",
       "4     1.001209e+06  2020-07-09      0.000115 2020-07-09\n",
       "..             ...         ...           ...        ...\n",
       "499   9.242817e+05  2022-06-27     -0.007164 2022-06-27\n",
       "500   9.013652e+05  2022-06-28     -0.024794 2022-06-28\n",
       "501   8.900220e+05  2022-06-29     -0.012584 2022-06-29\n",
       "502   8.799103e+05  2022-06-30     -0.011361 2022-06-30\n",
       "503   8.644041e+05  2022-07-01     -0.017623 2022-07-01\n",
       "\n",
       "[504 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HggausPRoCem",
    "outputId": "5e1cc98c-2654-482c-e0ef-84bc74d43443",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Compare to DJIA===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (504, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2020-07-02</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2022-07-01</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>24</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>-7.027%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>-13.56%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>25.673%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-39.979%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-3.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Worst drawdown periods</th>\n",
       "      <th>Net drawdown in %</th>\n",
       "      <th>Peak date</th>\n",
       "      <th>Valley date</th>\n",
       "      <th>Recovery date</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.98</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.23</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.87</td>\n",
       "      <td>2021-11-08</td>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>2021-11-19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.71</td>\n",
       "      <td>2020-12-22</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-01-12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.32</td>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>2021-11-26</td>\n",
       "      <td>2021-11-29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Stress Events</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Normal</th>\n",
       "      <td>-0.02%</td>\n",
       "      <td>-6.39%</td>\n",
       "      <td>7.41%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x5184 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value, \n",
    "             baseline_ticker = \"^NDX\", \n",
    "             baseline_start = df_account_value.loc[0,'date'],\n",
    "             baseline_end = df_account_value.loc[len(df_account_value)-1,'date'],\n",
    "             value_col_name=\"account_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkdWMUWKoCem"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "finRL",
   "language": "python",
   "name": "finrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "51c49a0b2976a7aa599cb0ec658b6ede5d1ee847d53b068743dcdf190843abdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
